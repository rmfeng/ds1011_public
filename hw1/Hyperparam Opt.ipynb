{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 4.63 ms\n"
     ]
    }
   ],
   "source": [
    "import ModelManager as mm_mod\n",
    "import config_defaults as cd\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Model and Data pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.27 ms\n"
     ]
    }
   ],
   "source": [
    "reload(mm_mod)\n",
    "reload(cd)\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': 0.01,\n",
       " 'NEPOCH': 10,\n",
       " 'BATCH_SIZE': 32,\n",
       " 'NGRAM_SIZE': 2,\n",
       " 'VOC_SIZE': 10000,\n",
       " 'EMBEDDING_DIM': 100,\n",
       " 'NGRAM_MODE': 'naive',\n",
       " 'VAL_SIZE': 5000,\n",
       " 'OPTIMIZER': torch.optim.adam.Adam,\n",
       " 'VAL_FREQ': 4,\n",
       " 'REMOVE_STOP_WORDS': True,\n",
       " 'REMOVE_PUNC': True,\n",
       " 'EARLY_STOP': True,\n",
       " 'EARLY_STOP_LOOKBACK': 4,\n",
       " 'EARLY_STOP_MIN_IMPROVE': 0.01}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 279 ms\n"
     ]
    }
   ],
   "source": [
    "mm = mm_mod.ModelManager()\n",
    "mm.hparams\n",
    "# mm = mm_mod.ModelManager(hparams=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 297 Âµs\n"
     ]
    }
   ],
   "source": [
    "#mm.load_data()\n",
    "#mm.data_to_pipe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting the ngrams for n = 1, 2, 3, 4 with both naive and spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting n-grams for: n=1, mode=naive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50e08d209844dbdb1a73c1f34cd8092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1294574577ba4e81b0aaf691bef3de18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=1, mode=spacy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a50bd4ba9d4ca6bdeabdbd8dead5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9560a59293814712ae606e25a7150e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=2, mode=naive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd9b2a3e1e94a9e8fa3af14964f7996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275095e94eaf4eaa9bcadc5b1c023dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=2, mode=spacy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7debf91d0d1a43708de70f2bae289322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b7a205a78f4abab0850cc8cf279952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=3, mode=naive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a06af447a1749679cc0d6656f124ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a8b0ca5a804da8ab7639a15a1c2e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=3, mode=spacy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6babf072753f42e1a4b485bad1d59632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d6438fb01a4ab8a17289c39957cf1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=4, mode=naive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ec1aab2534413ba240d50a7067774d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c376622e97fe4014ac8e77d9bf648a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=4, mode=spacy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438db716c97548b2aafe59e4e07bb55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05221ad27d5f4f0483ed2888c279f8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 1h 22min 45s\n"
     ]
    }
   ],
   "source": [
    "n_list = (1, 2, 3, 4)\n",
    "mode_list = ('naive', 'spacy')\n",
    "\n",
    "for n in n_list:\n",
    "    for mode in mode_list:\n",
    "        print(\"extracting n-grams for: n=%s, mode=%s\" % (n, mode))\n",
    "        param_overrides = {'NGRAM_MODE': mode,\n",
    "                           'NGRAM_SIZE': n}\n",
    "        mm = mm_mod.ModelManager(hparams=param_overrides)\n",
    "        mm.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to find a good LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list_exp_neg = np.arange(1,6)\n",
    "lr_list_neg = 1 / np.power(10, lr_list_exp_neg)\n",
    "lr_list_exp_pos = np.arange(0,3)\n",
    "lr_list_pos = np.power(10, lr_list_exp_pos)\n",
    "\n",
    "lr_list = np.append(lr_list_neg, lr_list_pos)\n",
    "lr_list.sort()\n",
    "print(lr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training all of these through 1 epoch and seeing results\n",
    "mm.res_df = None  # reset the results dataframe\n",
    "for cur_lr in lr_list:\n",
    "    # overriding some hyperparameters\n",
    "    print(\"training for lr = %s\" % cur_lr)\n",
    "    param_overrides = {'LR': cur_lr,\n",
    "                       'EARLY_STOP': False}\n",
    "    mm.hparams.update(param_overrides)\n",
    "    mm.train(epoch_override=1, reload_data=False)  \n",
    "display(mm.res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log10(mm.res_df['LR']), mm.res_df['final_val_acc'])\n",
    "plt.title('Validation Error after 1 epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mm.save_results(res_name='lr_explore.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for each ngram param, find the right vocabulary size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mm_mod)\n",
    "logger.setLevel(logging.WARNING)\n",
    "voc_sizes = np.arange(1, 9) * 10000\n",
    "n_list = (1, 2, 3, 4)\n",
    "mode_list = ('naive', 'spacy')\n",
    "\n",
    "for n in n_list:\n",
    "    for mode in mode_list:\n",
    "        for voc_size in voc_sizes:\n",
    "            start_time = time.time()\n",
    "            print(\"training models for: n=%s, mode=%s, voc_size=%s\" % (n, mode, voc_size))\n",
    "            param_overrides = {'NGRAM_MODE': mode,\n",
    "                               'NGRAM_SIZE': n,\n",
    "                               'VOC_SIZE': voc_size}\n",
    "            mm = mm_mod.ModelManager(hparams=param_overrides, res_name='vocab_explore.p')\n",
    "            mm.train()\n",
    "            print(\"Final Validation Acc = %s (train time: %.1fs)\\n\" % (mm.validation_acc_history[-1], \n",
    "                                                                  time.time() - start_time))\n",
    "    \n",
    "            mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mm.res_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(mm_mod)\n",
    "logger.setLevel(logging.INFO)\n",
    "param_overrides = {'NGRAM_MODE': 'naive',\n",
    "                   'NGRAM_SIZE': 4,\n",
    "                   'VOC_SIZE': 10000}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='vocab_explore.p')\n",
    "mm.load_data()\n",
    "mm.data_to_pipe()\n",
    "mm.model_init()  # make sure we force the model to re-init\n",
    "err = mm.training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = mm.data['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = mm.data['val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first check all of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "\n",
    "for datum in tqdm(val):\n",
    "    all_tokens += datum.token_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tk in all_tokens:\n",
    "    if not isinstance(tk, int):\n",
    "        print(tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(all_tokens)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
