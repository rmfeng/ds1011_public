{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ModelManager as mm_mod\n",
    "import config_defaults as cd\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Model and Data pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:40:34,388 root         INFO     initialized model with hyperparametrs:\n",
      "2018-09-30 19:40:34,389 root         INFO     LR: 0.01\n",
      "2018-09-30 19:40:34,389 root         INFO     NEPOCH: 10\n",
      "2018-09-30 19:40:34,389 root         INFO     BATCH_SIZE: 32\n",
      "2018-09-30 19:40:34,390 root         INFO     NGRAM_SIZE: 2\n",
      "2018-09-30 19:40:34,391 root         INFO     VOC_SIZE: 10000\n",
      "2018-09-30 19:40:34,391 root         INFO     EMBEDDING_DIM: 100\n",
      "2018-09-30 19:40:34,391 root         INFO     NGRAM_MODE: spacy\n",
      "2018-09-30 19:40:34,392 root         INFO     VAL_SIZE: 5000\n",
      "2018-09-30 19:40:34,392 root         INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-09-30 19:40:34,393 root         INFO     VAL_FREQ: 4\n",
      "2018-09-30 19:40:34,393 root         INFO     REMOVE_STOP_WORDS: True\n",
      "2018-09-30 19:40:34,393 root         INFO     REMOVE_PUNC: True\n",
      "2018-09-30 19:40:34,394 root         INFO     EARLY_STOP: True\n",
      "2018-09-30 19:40:34,394 root         INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-09-30 19:40:34,394 root         INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-09-30 19:40:34,395 root         INFO     allow pickle loads: True, allow pickle saves: True\n",
      "time: 10.5 ms\n"
     ]
    }
   ],
   "source": [
    "reload(mm_mod)\n",
    "reload(cd)\n",
    "param_overrides = {'NGRAM_MODE': 'spacy'}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides)\n",
    "# mm = mm_mod.ModelManager(hparams=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing SpaCy to Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:40:35,970 root         INFO     found pickle files in ./data/pickles/, loading them instead of rebuilding ... \n",
      "2018-09-30 19:40:39,113 root         INFO     constructing ngram_indexer ...\n",
      "2018-09-30 19:40:39,118 root         INFO     indexer length 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a94f26b61841979d491f26d474100d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2e61e0850c4f3eae7a0f7a464fb1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 19:40:41,193 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7a1ea5b9864c0bb0ae5b9df212d11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 19:40:41,809 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5cc5c575a34714952d3e9bbd92ce0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 6.79 s\n"
     ]
    }
   ],
   "source": [
    "mm.load_data()\n",
    "mm.data_to_pipe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting the ngrams for n = 1, 2, 3, 4 with both naive and spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting n-grams for: n=1, mode=naive\n",
      "2018-09-30 19:50:37,264 root         INFO     initialized model with hyperparametrs:\n",
      "2018-09-30 19:50:37,265 root         INFO     LR: 100.0\n",
      "2018-09-30 19:50:37,266 root         INFO     NEPOCH: 10\n",
      "2018-09-30 19:50:37,266 root         INFO     BATCH_SIZE: 32\n",
      "2018-09-30 19:50:37,266 root         INFO     NGRAM_SIZE: 1\n",
      "2018-09-30 19:50:37,267 root         INFO     VOC_SIZE: 10000\n",
      "2018-09-30 19:50:37,267 root         INFO     EMBEDDING_DIM: 100\n",
      "2018-09-30 19:50:37,268 root         INFO     NGRAM_MODE: naive\n",
      "2018-09-30 19:50:37,268 root         INFO     VAL_SIZE: 5000\n",
      "2018-09-30 19:50:37,268 root         INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-09-30 19:50:37,269 root         INFO     VAL_FREQ: 4\n",
      "2018-09-30 19:50:37,270 root         INFO     REMOVE_STOP_WORDS: True\n",
      "2018-09-30 19:50:37,270 root         INFO     REMOVE_PUNC: True\n",
      "2018-09-30 19:50:37,271 root         INFO     EARLY_STOP: False\n",
      "2018-09-30 19:50:37,271 root         INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-09-30 19:50:37,271 root         INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-09-30 19:50:37,272 root         INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-09-30 19:50:37,490 root         INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "2018-09-30 19:50:37,490 root         INFO     loading datasets ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8fb914e07a43df878180480879d5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade81380f074497797e070481ae8264a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 19:50:38,685 root         INFO     extracting ngram from training and val set of size 25000...\n",
      "2018-09-30 19:50:38,685 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ad312fc6f24364aa0f795aa19d9228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 19:50:41,223 root         INFO     extracting ngram from test set of size 25000 ...\n",
      "2018-09-30 19:50:41,224 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322fc8474ea0425c8cb563c834359e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 19:50:43,683 root         INFO     saving pickled data to folder ./data/pickles/ ...\n",
      "2018-09-30 19:50:45,573 root         INFO     constructing ngram_indexer ...\n",
      "2018-09-30 19:50:45,575 root         INFO     indexer length 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09436513cfda44b0adf9ea8c9b502998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23112f7f99a743869d898ad569cc0021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 19:50:46,333 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1dfb84cf284b748704ba82bf7c1753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 19:50:46,640 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a862e8df1f49b9903cec50a77fd2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=1, mode=spacy\n",
      "2018-09-30 19:50:46,947 root         INFO     initialized model with hyperparametrs:\n",
      "2018-09-30 19:50:46,947 root         INFO     LR: 100.0\n",
      "2018-09-30 19:50:46,947 root         INFO     NEPOCH: 10\n",
      "2018-09-30 19:50:46,948 root         INFO     BATCH_SIZE: 32\n",
      "2018-09-30 19:50:46,949 root         INFO     NGRAM_SIZE: 1\n",
      "2018-09-30 19:50:46,949 root         INFO     VOC_SIZE: 10000\n",
      "2018-09-30 19:50:46,950 root         INFO     EMBEDDING_DIM: 100\n",
      "2018-09-30 19:50:46,950 root         INFO     NGRAM_MODE: spacy\n",
      "2018-09-30 19:50:46,952 root         INFO     VAL_SIZE: 5000\n",
      "2018-09-30 19:50:46,952 root         INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-09-30 19:50:46,952 root         INFO     VAL_FREQ: 4\n",
      "2018-09-30 19:50:46,952 root         INFO     REMOVE_STOP_WORDS: True\n",
      "2018-09-30 19:50:46,954 root         INFO     REMOVE_PUNC: True\n",
      "2018-09-30 19:50:46,954 root         INFO     EARLY_STOP: False\n",
      "2018-09-30 19:50:46,954 root         INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-09-30 19:50:46,955 root         INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-09-30 19:50:46,956 root         INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-09-30 19:50:47,070 root         INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "2018-09-30 19:50:47,075 root         INFO     loading datasets ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb2a6b80f0a4d7e8e4adcc972327b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a116bcd5ef864a28ab210ea35b96fa2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 19:50:48,305 root         INFO     extracting ngram from training and val set of size 25000...\n",
      "2018-09-30 19:50:48,305 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07af14fc772b4ec88917f7afffe36fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:03:54,218 root         INFO     extracting ngram from test set of size 25000 ...\n",
      "2018-09-30 20:03:54,218 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5f27594e194741b43a7dea6c1445f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:16:46,871 root         INFO     saving pickled data to folder ./data/pickles/ ...\n",
      "2018-09-30 20:16:48,736 root         INFO     constructing ngram_indexer ...\n",
      "2018-09-30 20:16:48,739 root         INFO     indexer length 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae99e77bd3e747e08f04846d772c389c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbb5d551b3148419d005e12674c68b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:16:49,342 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b05fc128b74e8d97b08ad162b7cba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:16:49,638 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ba8e7aac32436c99b22eec5d66a72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=2, mode=naive\n",
      "2018-09-30 20:16:49,933 root         INFO     initialized model with hyperparametrs:\n",
      "2018-09-30 20:16:49,933 root         INFO     LR: 100.0\n",
      "2018-09-30 20:16:49,933 root         INFO     NEPOCH: 10\n",
      "2018-09-30 20:16:49,934 root         INFO     BATCH_SIZE: 32\n",
      "2018-09-30 20:16:49,934 root         INFO     NGRAM_SIZE: 2\n",
      "2018-09-30 20:16:49,934 root         INFO     VOC_SIZE: 10000\n",
      "2018-09-30 20:16:49,935 root         INFO     EMBEDDING_DIM: 100\n",
      "2018-09-30 20:16:49,935 root         INFO     NGRAM_MODE: naive\n",
      "2018-09-30 20:16:49,935 root         INFO     VAL_SIZE: 5000\n",
      "2018-09-30 20:16:49,936 root         INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-09-30 20:16:49,938 root         INFO     VAL_FREQ: 4\n",
      "2018-09-30 20:16:49,938 root         INFO     REMOVE_STOP_WORDS: True\n",
      "2018-09-30 20:16:49,938 root         INFO     REMOVE_PUNC: True\n",
      "2018-09-30 20:16:49,939 root         INFO     EARLY_STOP: False\n",
      "2018-09-30 20:16:49,939 root         INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-09-30 20:16:49,939 root         INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-09-30 20:16:49,939 root         INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-09-30 20:16:50,053 root         INFO     found pickle files in ./data/pickles/, loading them instead of rebuilding ... \n",
      "2018-09-30 20:16:53,231 root         INFO     constructing ngram_indexer ...\n",
      "2018-09-30 20:16:53,235 root         INFO     indexer length 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6b6fec2768489584ede9bb5f35815a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ba725e0f1340c186da61ec48a10e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:16:55,470 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40037982e8f54e6d8f95e4391bf2fbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:16:56,374 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a11364f77584e84b2ae7c092bcd41ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=2, mode=spacy\n",
      "2018-09-30 20:16:56,960 root         INFO     initialized model with hyperparametrs:\n",
      "2018-09-30 20:16:56,960 root         INFO     LR: 100.0\n",
      "2018-09-30 20:16:56,960 root         INFO     NEPOCH: 10\n",
      "2018-09-30 20:16:56,961 root         INFO     BATCH_SIZE: 32\n",
      "2018-09-30 20:16:56,961 root         INFO     NGRAM_SIZE: 2\n",
      "2018-09-30 20:16:56,961 root         INFO     VOC_SIZE: 10000\n",
      "2018-09-30 20:16:56,962 root         INFO     EMBEDDING_DIM: 100\n",
      "2018-09-30 20:16:56,963 root         INFO     NGRAM_MODE: spacy\n",
      "2018-09-30 20:16:56,963 root         INFO     VAL_SIZE: 5000\n",
      "2018-09-30 20:16:56,964 root         INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-09-30 20:16:56,964 root         INFO     VAL_FREQ: 4\n",
      "2018-09-30 20:16:56,964 root         INFO     REMOVE_STOP_WORDS: True\n",
      "2018-09-30 20:16:56,964 root         INFO     REMOVE_PUNC: True\n",
      "2018-09-30 20:16:56,965 root         INFO     EARLY_STOP: False\n",
      "2018-09-30 20:16:56,965 root         INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-09-30 20:16:56,965 root         INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-09-30 20:16:56,965 root         INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-09-30 20:16:57,188 root         INFO     found pickle files in ./data/pickles/, loading them instead of rebuilding ... \n",
      "2018-09-30 20:17:00,251 root         INFO     constructing ngram_indexer ...\n",
      "2018-09-30 20:17:00,254 root         INFO     indexer length 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81ba632c13e441899194065f29d4197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeed027b8a94663b68503d7a01c4213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:17:02,308 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49236c0ed28d4e4a97b221ff3c3b832a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:17:03,207 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023b919e40c24e688717a57d0923c430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=3, mode=naive\n",
      "2018-09-30 20:17:03,809 root         INFO     initialized model with hyperparametrs:\n",
      "2018-09-30 20:17:03,810 root         INFO     LR: 100.0\n",
      "2018-09-30 20:17:03,810 root         INFO     NEPOCH: 10\n",
      "2018-09-30 20:17:03,810 root         INFO     BATCH_SIZE: 32\n",
      "2018-09-30 20:17:03,811 root         INFO     NGRAM_SIZE: 3\n",
      "2018-09-30 20:17:03,813 root         INFO     VOC_SIZE: 10000\n",
      "2018-09-30 20:17:03,814 root         INFO     EMBEDDING_DIM: 100\n",
      "2018-09-30 20:17:03,814 root         INFO     NGRAM_MODE: naive\n",
      "2018-09-30 20:17:03,815 root         INFO     VAL_SIZE: 5000\n",
      "2018-09-30 20:17:03,816 root         INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-09-30 20:17:03,816 root         INFO     VAL_FREQ: 4\n",
      "2018-09-30 20:17:03,816 root         INFO     REMOVE_STOP_WORDS: True\n",
      "2018-09-30 20:17:03,816 root         INFO     REMOVE_PUNC: True\n",
      "2018-09-30 20:17:03,817 root         INFO     EARLY_STOP: False\n",
      "2018-09-30 20:17:03,817 root         INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-09-30 20:17:03,817 root         INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-09-30 20:17:03,817 root         INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-09-30 20:17:04,035 root         INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "2018-09-30 20:17:04,038 root         INFO     loading datasets ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bef6a1e7f19450eafc5d3683b3a008c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d6773a6c154b95810ee3a5ad452ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:17:05,195 root         INFO     extracting ngram from training and val set of size 25000...\n",
      "2018-09-30 20:17:05,195 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f501f9764044779c050a2950994e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:17:11,657 root         INFO     extracting ngram from test set of size 25000 ...\n",
      "2018-09-30 20:17:11,658 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926eac629d244a51b895d46e1c3013c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:17:18,331 root         INFO     saving pickled data to folder ./data/pickles/ ...\n",
      "2018-09-30 20:17:23,996 root         INFO     constructing ngram_indexer ...\n",
      "2018-09-30 20:17:23,998 root         INFO     indexer length 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e25012a5f474461b7db622eee88d4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d1337ee0f143e8b094a237089ce45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:17:27,582 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a3cc5b64b144f0802ec8274acce665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:17:28,406 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027861d25e5c4d649ab8fac55f06c615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=3, mode=spacy\n",
      "2018-09-30 20:17:29,260 root         INFO     initialized model with hyperparametrs:\n",
      "2018-09-30 20:17:29,260 root         INFO     LR: 100.0\n",
      "2018-09-30 20:17:29,260 root         INFO     NEPOCH: 10\n",
      "2018-09-30 20:17:29,261 root         INFO     BATCH_SIZE: 32\n",
      "2018-09-30 20:17:29,261 root         INFO     NGRAM_SIZE: 3\n",
      "2018-09-30 20:17:29,261 root         INFO     VOC_SIZE: 10000\n",
      "2018-09-30 20:17:29,261 root         INFO     EMBEDDING_DIM: 100\n",
      "2018-09-30 20:17:29,262 root         INFO     NGRAM_MODE: spacy\n",
      "2018-09-30 20:17:29,262 root         INFO     VAL_SIZE: 5000\n",
      "2018-09-30 20:17:29,262 root         INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-09-30 20:17:29,263 root         INFO     VAL_FREQ: 4\n",
      "2018-09-30 20:17:29,263 root         INFO     REMOVE_STOP_WORDS: True\n",
      "2018-09-30 20:17:29,263 root         INFO     REMOVE_PUNC: True\n",
      "2018-09-30 20:17:29,263 root         INFO     EARLY_STOP: False\n",
      "2018-09-30 20:17:29,264 root         INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-09-30 20:17:29,265 root         INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-09-30 20:17:29,265 root         INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-09-30 20:17:29,593 root         INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "2018-09-30 20:17:29,597 root         INFO     loading datasets ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432ef9cd49f44cadbd5264fd804a18be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e166187342849c0bd80ff8419e00224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:17:30,797 root         INFO     extracting ngram from training and val set of size 25000...\n",
      "2018-09-30 20:17:30,798 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b4db92a8e74c46948142fe2e2dea81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:30:16,020 root         INFO     extracting ngram from test set of size 25000 ...\n",
      "2018-09-30 20:30:16,021 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32e44077f524278a691a15b3aacaa0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:41:29,162 root         INFO     saving pickled data to folder ./data/pickles/ ...\n",
      "2018-09-30 20:41:34,388 root         INFO     constructing ngram_indexer ...\n",
      "2018-09-30 20:41:34,390 root         INFO     indexer length 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76190baa467e4409a0c4e4b194fe8e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66983d28fcc347b48920f5400b14d1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:41:37,836 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de552e463b64e09bea19de50082b071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:41:39,103 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcd109d07374f59858956ca102cded2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=4, mode=naive\n",
      "2018-09-30 20:41:39,957 root         INFO     initialized model with hyperparametrs:\n",
      "2018-09-30 20:41:39,958 root         INFO     LR: 100.0\n",
      "2018-09-30 20:41:39,958 root         INFO     NEPOCH: 10\n",
      "2018-09-30 20:41:39,958 root         INFO     BATCH_SIZE: 32\n",
      "2018-09-30 20:41:39,959 root         INFO     NGRAM_SIZE: 4\n",
      "2018-09-30 20:41:39,959 root         INFO     VOC_SIZE: 10000\n",
      "2018-09-30 20:41:39,959 root         INFO     EMBEDDING_DIM: 100\n",
      "2018-09-30 20:41:39,960 root         INFO     NGRAM_MODE: naive\n",
      "2018-09-30 20:41:39,960 root         INFO     VAL_SIZE: 5000\n",
      "2018-09-30 20:41:39,960 root         INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-09-30 20:41:39,960 root         INFO     VAL_FREQ: 4\n",
      "2018-09-30 20:41:39,961 root         INFO     REMOVE_STOP_WORDS: True\n",
      "2018-09-30 20:41:39,961 root         INFO     REMOVE_PUNC: True\n",
      "2018-09-30 20:41:39,961 root         INFO     EARLY_STOP: False\n",
      "2018-09-30 20:41:39,961 root         INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-09-30 20:41:39,962 root         INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-09-30 20:41:39,962 root         INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-09-30 20:41:40,287 root         INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "2018-09-30 20:41:40,290 root         INFO     loading datasets ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fda27239c24e12898d4a766362737b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ee3ab248b245189b37d3bd72059b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:41:41,432 root         INFO     extracting ngram from training and val set of size 25000...\n",
      "2018-09-30 20:41:41,432 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e062d101586646f0974e0b0aa473ae5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:41:49,992 root         INFO     extracting ngram from test set of size 25000 ...\n",
      "2018-09-30 20:41:49,992 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e07379811e4a89a40367dfb1ea29c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:41:58,702 root         INFO     saving pickled data to folder ./data/pickles/ ...\n",
      "2018-09-30 20:42:07,246 root         INFO     constructing ngram_indexer ...\n",
      "2018-09-30 20:42:07,248 root         INFO     indexer length 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de0ba0030374ac48883a58795a5427a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46253826b2ae4e4d8672eb0b3df22132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:42:12,318 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b12beb75f8e47999848e8b7fffc4932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:42:13,330 root         INFO     setting each dataset's token indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1688d8ff9b425d85c33b27fa650a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='token to index', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting n-grams for: n=4, mode=spacy\n",
      "2018-09-30 20:42:14,378 root         INFO     initialized model with hyperparametrs:\n",
      "2018-09-30 20:42:14,379 root         INFO     LR: 100.0\n",
      "2018-09-30 20:42:14,379 root         INFO     NEPOCH: 10\n",
      "2018-09-30 20:42:14,379 root         INFO     BATCH_SIZE: 32\n",
      "2018-09-30 20:42:14,380 root         INFO     NGRAM_SIZE: 4\n",
      "2018-09-30 20:42:14,380 root         INFO     VOC_SIZE: 10000\n",
      "2018-09-30 20:42:14,380 root         INFO     EMBEDDING_DIM: 100\n",
      "2018-09-30 20:42:14,381 root         INFO     NGRAM_MODE: spacy\n",
      "2018-09-30 20:42:14,381 root         INFO     VAL_SIZE: 5000\n",
      "2018-09-30 20:42:14,381 root         INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-09-30 20:42:14,383 root         INFO     VAL_FREQ: 4\n",
      "2018-09-30 20:42:14,384 root         INFO     REMOVE_STOP_WORDS: True\n",
      "2018-09-30 20:42:14,384 root         INFO     REMOVE_PUNC: True\n",
      "2018-09-30 20:42:14,384 root         INFO     EARLY_STOP: False\n",
      "2018-09-30 20:42:14,384 root         INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-09-30 20:42:14,385 root         INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-09-30 20:42:14,385 root         INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-09-30 20:42:14,820 root         INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "2018-09-30 20:42:14,827 root         INFO     loading datasets ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3600eea2f84640f59d03e70af8114667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ed1dd084a24a2192df1f51f20b33f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:42:15,969 root         INFO     extracting ngram from training and val set of size 25000...\n",
      "2018-09-30 20:42:15,969 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef041e0926c5429eab3282c007c6ef5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-09-30 20:53:54,307 root         INFO     extracting ngram from test set of size 25000 ...\n",
      "2018-09-30 20:53:54,308 root         INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8901156d2354d99b1fb5ea8e4eb8418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extract ngrams', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_list = (1, 2, 3, 4)\n",
    "mode_list = ('naive', 'spacy')\n",
    "\n",
    "for n in n_list:\n",
    "    for mode in mode_list:\n",
    "        print(\"extracting n-grams for: n=%s, mode=%s\" % (n, mode))\n",
    "        param_overrides = {'NGRAM_MODE': mode,\n",
    "                           'NGRAM_SIZE': n}\n",
    "        mm = mm_mod.ModelManager(hparams=param_overrides)\n",
    "        mm.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to find a good LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]\n",
      "time: 1.51 ms\n"
     ]
    }
   ],
   "source": [
    "lr_list_exp_neg = np.arange(1,6)\n",
    "lr_list_neg = 1 / np.power(10, lr_list_exp_neg)\n",
    "lr_list_exp_pos = np.arange(0,3)\n",
    "lr_list_pos = np.power(10, lr_list_exp_pos)\n",
    "\n",
    "lr_list = np.append(lr_list_neg, lr_list_pos)\n",
    "lr_list.sort()\n",
    "print(lr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a4abd822194b34b9987d7b19aac0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57f699ea6654ba590be372bb14271e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=625), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:40:50,475 root         INFO     Epoch: [1/10], Step: [128/625], Validation Acc: 54.48\n",
      "2018-09-30 19:40:51,314 root         INFO     Epoch: [1/10], Step: [256/625], Validation Acc: 54.8\n",
      "2018-09-30 19:40:52,145 root         INFO     Epoch: [1/10], Step: [384/625], Validation Acc: 54.94\n",
      "2018-09-30 19:40:52,973 root         INFO     Epoch: [1/10], Step: [512/625], Validation Acc: 54.98\n",
      "\n",
      "2018-09-30 19:40:53,463 root         INFO     generating new pandas dataframe to store results\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58726098c8a34ba881625d37e2aa83ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be41d0a494c7422c9e919bef0c26aeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=625), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:40:55,254 root         INFO     Epoch: [1/10], Step: [128/625], Validation Acc: 50.18\n",
      "2018-09-30 19:40:56,089 root         INFO     Epoch: [1/10], Step: [256/625], Validation Acc: 54.64\n",
      "2018-09-30 19:40:56,921 root         INFO     Epoch: [1/10], Step: [384/625], Validation Acc: 56.3\n",
      "2018-09-30 19:40:57,764 root         INFO     Epoch: [1/10], Step: [512/625], Validation Acc: 58.92\n",
      "\n",
      "2018-09-30 19:40:58,258 root         INFO     appending new results to existing dataframe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a767eb9ab328409f8df8a2e9f30465fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0073f7d6e6e42fcaaddf7a9b93156f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=625), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:40:59,992 root         INFO     Epoch: [1/10], Step: [128/625], Validation Acc: 60.9\n",
      "2018-09-30 19:41:00,810 root         INFO     Epoch: [1/10], Step: [256/625], Validation Acc: 64.16\n",
      "2018-09-30 19:41:01,636 root         INFO     Epoch: [1/10], Step: [384/625], Validation Acc: 71.54\n",
      "2018-09-30 19:41:02,459 root         INFO     Epoch: [1/10], Step: [512/625], Validation Acc: 72.38\n",
      "\n",
      "2018-09-30 19:41:02,942 root         INFO     appending new results to existing dataframe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef948dcda134b3f92431e61375d325e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8959d1fb194101a42b01380b513a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=625), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:41:04,772 root         INFO     Epoch: [1/10], Step: [128/625], Validation Acc: 82.78\n",
      "2018-09-30 19:41:05,604 root         INFO     Epoch: [1/10], Step: [256/625], Validation Acc: 86.24\n",
      "2018-09-30 19:41:06,426 root         INFO     Epoch: [1/10], Step: [384/625], Validation Acc: 86.7\n",
      "2018-09-30 19:41:07,320 root         INFO     Epoch: [1/10], Step: [512/625], Validation Acc: 86.78\n",
      "\n",
      "2018-09-30 19:41:07,842 root         INFO     appending new results to existing dataframe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baef4aec62ef49bbb8e747905accd8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317384836dac49f381310efa576f813e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=625), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:41:09,664 root         INFO     Epoch: [1/10], Step: [128/625], Validation Acc: 84.32\n",
      "2018-09-30 19:41:10,491 root         INFO     Epoch: [1/10], Step: [256/625], Validation Acc: 85.34\n",
      "2018-09-30 19:41:11,355 root         INFO     Epoch: [1/10], Step: [384/625], Validation Acc: 86.76\n",
      "2018-09-30 19:41:12,243 root         INFO     Epoch: [1/10], Step: [512/625], Validation Acc: 87.4\n",
      "\n",
      "2018-09-30 19:41:12,752 root         INFO     appending new results to existing dataframe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a1f9c8525b487ca5168798836124ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31dcd1f2f284b2ca04977c6d9ddbd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=625), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:41:14,510 root         INFO     Epoch: [1/10], Step: [128/625], Validation Acc: 72.72\n",
      "2018-09-30 19:41:15,343 root         INFO     Epoch: [1/10], Step: [256/625], Validation Acc: 83.06\n",
      "2018-09-30 19:41:16,242 root         INFO     Epoch: [1/10], Step: [384/625], Validation Acc: 81.04\n",
      "2018-09-30 19:41:17,103 root         INFO     Epoch: [1/10], Step: [512/625], Validation Acc: 82.16\n",
      "\n",
      "2018-09-30 19:41:17,599 root         INFO     appending new results to existing dataframe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c3883a383c443384e8e457a9d00b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e40053b5e542d0ae1a362ca019331c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=625), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:41:19,314 root         INFO     Epoch: [1/10], Step: [128/625], Validation Acc: 75.24\n",
      "2018-09-30 19:41:20,139 root         INFO     Epoch: [1/10], Step: [256/625], Validation Acc: 81.0\n",
      "2018-09-30 19:41:20,965 root         INFO     Epoch: [1/10], Step: [384/625], Validation Acc: 70.72\n",
      "2018-09-30 19:41:21,861 root         INFO     Epoch: [1/10], Step: [512/625], Validation Acc: 79.78\n",
      "\n",
      "2018-09-30 19:41:22,370 root         INFO     appending new results to existing dataframe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5702bf2ce15b45d8a8380617742470e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d450d114c34b13a1f413700b9582cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=625), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:41:24,279 root         INFO     Epoch: [1/10], Step: [128/625], Validation Acc: 64.4\n",
      "2018-09-30 19:41:25,166 root         INFO     Epoch: [1/10], Step: [256/625], Validation Acc: 68.68\n",
      "2018-09-30 19:41:26,094 root         INFO     Epoch: [1/10], Step: [384/625], Validation Acc: 70.5\n",
      "2018-09-30 19:41:26,940 root         INFO     Epoch: [1/10], Step: [512/625], Validation Acc: 82.76\n",
      "\n",
      "2018-09-30 19:41:27,515 root         INFO     appending new results to existing dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_val_acc</th>\n",
       "      <th>epoch1_val_acc</th>\n",
       "      <th>epoch2_val_acc</th>\n",
       "      <th>epoch3_val_acc</th>\n",
       "      <th>final_val_acc</th>\n",
       "      <th>training_time</th>\n",
       "      <th>total_data_iterated</th>\n",
       "      <th>early_stopped</th>\n",
       "      <th>pct_unk_train</th>\n",
       "      <th>pct_unk_val</th>\n",
       "      <th>...</th>\n",
       "      <th>EMBEDDING_DIM</th>\n",
       "      <th>NGRAM_MODE</th>\n",
       "      <th>VAL_SIZE</th>\n",
       "      <th>OPTIMIZER</th>\n",
       "      <th>VAL_FREQ</th>\n",
       "      <th>REMOVE_STOP_WORDS</th>\n",
       "      <th>REMOVE_PUNC</th>\n",
       "      <th>EARLY_STOP</th>\n",
       "      <th>EARLY_STOP_LOOKBACK</th>\n",
       "      <th>EARLY_STOP_MIN_IMPROVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>54.98</td>\n",
       "      <td>4.57</td>\n",
       "      <td>20000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.530094</td>\n",
       "      <td>0.534054</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>spacy</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>58.92</td>\n",
       "      <td>4.51</td>\n",
       "      <td>20000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.530094</td>\n",
       "      <td>0.534054</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>spacy</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>72.38</td>\n",
       "      <td>4.4</td>\n",
       "      <td>20000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.530094</td>\n",
       "      <td>0.534054</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>spacy</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>86.78</td>\n",
       "      <td>4.62</td>\n",
       "      <td>20000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.530094</td>\n",
       "      <td>0.534054</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>spacy</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>87.40</td>\n",
       "      <td>4.61</td>\n",
       "      <td>20000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.530094</td>\n",
       "      <td>0.534054</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>spacy</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>82.16</td>\n",
       "      <td>4.55</td>\n",
       "      <td>20000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.530094</td>\n",
       "      <td>0.534054</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>spacy</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>79.78</td>\n",
       "      <td>4.49</td>\n",
       "      <td>20000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.530094</td>\n",
       "      <td>0.534054</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>spacy</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>82.76</td>\n",
       "      <td>4.82</td>\n",
       "      <td>20000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.530094</td>\n",
       "      <td>0.534054</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>spacy</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  initial_val_acc epoch1_val_acc epoch2_val_acc epoch3_val_acc  final_val_acc  \\\n",
       "1                                                                       54.98   \n",
       "2                                                                       58.92   \n",
       "3                                                                       72.38   \n",
       "4                                                                       86.78   \n",
       "5                                                                       87.40   \n",
       "6                                                                       82.16   \n",
       "7                                                                       79.78   \n",
       "8                                                                       82.76   \n",
       "\n",
       "  training_time  total_data_iterated early_stopped  pct_unk_train  \\\n",
       "1          4.57                20000         False       0.530094   \n",
       "2          4.51                20000         False       0.530094   \n",
       "3           4.4                20000         False       0.530094   \n",
       "4          4.62                20000         False       0.530094   \n",
       "5          4.61                20000         False       0.530094   \n",
       "6          4.55                20000         False       0.530094   \n",
       "7          4.49                20000         False       0.530094   \n",
       "8          4.82                20000         False       0.530094   \n",
       "\n",
       "   pct_unk_val           ...            EMBEDDING_DIM  NGRAM_MODE  VAL_SIZE  \\\n",
       "1     0.534054           ...                      100       spacy      5000   \n",
       "2     0.534054           ...                      100       spacy      5000   \n",
       "3     0.534054           ...                      100       spacy      5000   \n",
       "4     0.534054           ...                      100       spacy      5000   \n",
       "5     0.534054           ...                      100       spacy      5000   \n",
       "6     0.534054           ...                      100       spacy      5000   \n",
       "7     0.534054           ...                      100       spacy      5000   \n",
       "8     0.534054           ...                      100       spacy      5000   \n",
       "\n",
       "                         OPTIMIZER  VAL_FREQ  REMOVE_STOP_WORDS REMOVE_PUNC  \\\n",
       "1  <class 'torch.optim.adam.Adam'>         4               True        True   \n",
       "2  <class 'torch.optim.adam.Adam'>         4               True        True   \n",
       "3  <class 'torch.optim.adam.Adam'>         4               True        True   \n",
       "4  <class 'torch.optim.adam.Adam'>         4               True        True   \n",
       "5  <class 'torch.optim.adam.Adam'>         4               True        True   \n",
       "6  <class 'torch.optim.adam.Adam'>         4               True        True   \n",
       "7  <class 'torch.optim.adam.Adam'>         4               True        True   \n",
       "8  <class 'torch.optim.adam.Adam'>         4               True        True   \n",
       "\n",
       "   EARLY_STOP EARLY_STOP_LOOKBACK  EARLY_STOP_MIN_IMPROVE  \n",
       "1       False                   2                    0.01  \n",
       "2       False                   2                    0.01  \n",
       "3       False                   2                    0.01  \n",
       "4       False                   2                    0.01  \n",
       "5       False                   2                    0.01  \n",
       "6       False                   2                    0.01  \n",
       "7       False                   2                    0.01  \n",
       "8       False                   2                    0.01  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "# training all of these through 1 epoch and seeing results\n",
    "mm.res_df = None  # reset the results dataframe\n",
    "for cur_lr in lr_list:\n",
    "    # overriding some hyperparameters\n",
    "    param_overrides = {'LR': cur_lr,\n",
    "                       'EARLY_STOP': False}\n",
    "    mm.hparams.update(param_overrides)\n",
    "    mm.train(epoch_override=1, reload_data=False)  \n",
    "display(mm.res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 68 ms\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(np.log10(mm.res_df['LR']), mm.res_df['final_val_acc'])\n",
    "plt.title('Validation Error after 1 epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 19:44:18,341 root         INFO     results saved to ./data/lr_explore.p\n",
      "time: 1.55 ms\n"
     ]
    }
   ],
   "source": [
    "mm.save_results(res_name='lr_explore.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for each ngram param, find the right vocabulary size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_sizes = np.arange(1, 11) * 10000\n",
    "n_list = (1, 2, 3, 4)\n",
    "mode_list = ('naive', 'spacy')\n",
    "\n",
    "for n in n_list:\n",
    "    for mode in mode_list:\n",
    "        for voc_size in voc_sizes:\n",
    "            print(\"training models for: n=%s, mode=%s, voc_size=%s\" % (n, mode, voc_size))\n",
    "            param_overrides = {'NGRAM_MODE': mode,\n",
    "                               'NGRAM_SIZE': n,\n",
    "                               'VOC_SIZE': voc_size}\n",
    "            mm = mm_mod.ModelManager(hparams=param_overrides)\n",
    "            mm.train()\n",
    "display(mm.res_df)\n",
    "mm.save_results(res_name='vocab_explore.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
