{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 1.75 ms\n"
     ]
    }
   ],
   "source": [
    "import ModelManager as mm_mod\n",
    "import config_defaults as cd\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Model and Data pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.14 ms\n"
     ]
    }
   ],
   "source": [
    "reload(mm_mod)\n",
    "reload(cd)\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting the ngrams for n = 1, 2, 3, 4 with both naive and spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n_list = (1, 2, 3, 4)\n",
    "mode_list = ('naive', 'spacy')\n",
    "\n",
    "for n in n_list:\n",
    "    for mode in mode_list:\n",
    "        print(\"extracting n-grams for: n=%s, mode=%s\" % (n, mode))\n",
    "        param_overrides = {'NGRAM_MODE': mode,\n",
    "                           'NGRAM_SIZE': n}\n",
    "        mm = mm_mod.ModelManager(hparams=param_overrides)\n",
    "        mm.load_data()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the annealing of LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training all of these through 1 epoch and seeing results\n",
    "reload(mm_mod)\n",
    "mm = mm_mod.ModelManager()\n",
    "mm.load_data()\n",
    "mm.data_to_pipe()\n",
    "param_overrides = {'EARLY_STOP': False}\n",
    "mm.hparams.update(param_overrides)\n",
    "mm.train(epoch_override=3, reload_data=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to find a good LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list_exp_neg = np.arange(1,6)\n",
    "lr_list_neg = 1 / np.power(10, lr_list_exp_neg)\n",
    "lr_list_exp_pos = np.arange(0,3)\n",
    "lr_list_pos = np.power(10, lr_list_exp_pos)\n",
    "\n",
    "lr_list = np.append(lr_list_neg, lr_list_pos)\n",
    "lr_list.sort()\n",
    "print(lr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training all of these through 1 epoch and seeing results\n",
    "mm = mm_mod.ModelManager()\n",
    "mm.load_data()\n",
    "mm.data_to_pipe()\n",
    "\n",
    "mm.res_df = None  # reset the results dataframe\n",
    "for cur_lr in lr_list:\n",
    "    # overriding some hyperparameters\n",
    "    print(\"training for initial lr = %s\" % cur_lr)\n",
    "    param_overrides = {'LR': cur_lr,\n",
    "                       'EARLY_STOP': False}\n",
    "    mm.hparams.update(param_overrides)\n",
    "    mm.train(epoch_override=1, reload_data=False)  \n",
    "display(mm.res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log10(mm.res_df['LR']), mm.res_df['final_val_acc'])\n",
    "plt.title('Validation Error after 1 epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mm.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for each ngram param, find the right vocabulary size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mm_mod)\n",
    "logger.setLevel(logging.WARNING)\n",
    "voc_sizes = np.arange(1, 9) * 10000\n",
    "n_list = (1, 2, 3, 4)\n",
    "mode_list = ('naive', 'spacy')\n",
    "\n",
    "for n in n_list:\n",
    "    for mode in mode_list:\n",
    "        for voc_size in voc_sizes:\n",
    "            start_time = time.time()\n",
    "            print(\"training models for: n=%s, mode=%s, voc_size=%s\" % (n, mode, voc_size))\n",
    "            param_overrides = {'NGRAM_MODE': mode,\n",
    "                               'NGRAM_SIZE': n,\n",
    "                               'VOC_SIZE': voc_size}\n",
    "            mm = mm_mod.ModelManager(hparams=param_overrides, res_name='vocab_explore.p')\n",
    "            mm.train()\n",
    "            print(\"Final Validation Acc = %s (train time: %.1fs)\\n\" % (mm.validation_acc_history[-1], \n",
    "                                                                  time.time() - start_time))\n",
    "    \n",
    "            mm.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra vocabulary - for spacy ngram =4, the upper tail hasn't been fully explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_sizes = np.arange(9, 15) * 10000\n",
    "for voc_size in voc_sizes:\n",
    "    start_time = time.time()\n",
    "    print(\"training models for: n=4, mode=spacy, voc_size=%s\" % (voc_size))\n",
    "    param_overrides = {'NGRAM_MODE': 'spacy',\n",
    "                       'NGRAM_SIZE': 4,\n",
    "                       'VOC_SIZE': voc_size}\n",
    "    mm = mm_mod.ModelManager(hparams=param_overrides, res_name='voc_additional.p')\n",
    "    mm.train()\n",
    "    print(\"Final Validation Acc = %s (train time: %.1fs)\\n\" % (mm.validation_acc_history[-1], \n",
    "                                                          time.time() - start_time))\n",
    "\n",
    "    mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_sizes = np.arange(3, 11) * 100000\n",
    "voc_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we tried even larger vocabsizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_sizes = np.arange(3, 11) * 100000\n",
    "for voc_size in voc_sizes:\n",
    "    start_time = time.time()\n",
    "    print(\"training models for: n=4, mode=spacy, voc_size=%s\" % (voc_size))\n",
    "    param_overrides = {'NGRAM_MODE': 'spacy',\n",
    "                       'NGRAM_SIZE': 4,\n",
    "                       'VOC_SIZE': voc_size}\n",
    "    mm = mm_mod.ModelManager(hparams=param_overrides, res_name='voc_additional.p')\n",
    "    mm.train()\n",
    "    print(\"Final Validation Acc = %s (train time: %.1fs)\\n\" % (mm.validation_acc_history[-1], \n",
    "                                                          time.time() - start_time))\n",
    "\n",
    "    mm.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dims = np.arange(2, 15) * 50\n",
    "emb_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mm_mod)\n",
    "logger.setLevel(logging.WARNING)\n",
    "voc_sizes = np.arange(2, 13) * 10000\n",
    "emb_dims = np.arange(1, 15) * 50\n",
    "\n",
    "for emb_dim in emb_dims:\n",
    "    for voc_size in voc_sizes:\n",
    "        start_time = time.time()\n",
    "        print(\"training models for: emb_dim=%s, voc_size=%s\" % (emb_dim, voc_size))\n",
    "        param_overrides = {'VOC_SIZE': voc_size,\n",
    "                           'NGRAM_MODE':'spacy',\n",
    "                           'EMBEDDING_DIM':emb_dim}\n",
    "        mm = mm_mod.ModelManager(hparams=param_overrides, res_name='embdim.p')\n",
    "        mm.train()\n",
    "        print(\"Final Validation Acc = %s (train time: %.1fs)\\n\" % (mm.validation_acc_history[-1], \n",
    "                                                              time.time() - start_time))\n",
    "\n",
    "        mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mm.res_df['final_val_acc'].sort_values().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mm.res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_list = [torch.optim.RMSprop, torch.optim.Adagrad, torch.optim.Adam]\n",
    "\n",
    "for opt in opt_list:\n",
    "    start_time = time.time()\n",
    "    print(\"training models for: optimizer = %s\" % (str(opt)))\n",
    "    param_overrides = {'OPTIMIZER': opt}\n",
    "    mm = mm_mod.ModelManager(hparams=param_overrides, res_name='optim.p')\n",
    "    mm.train()\n",
    "    print(\"Final Validation Acc = %s (train time: %.1fs)\\n\" % (mm.validation_acc_history[-1], \n",
    "                                                          time.time() - start_time))\n",
    "\n",
    "    mm.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different LR decay rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_decays = 0.5 + np.arange(2, 11) * 0.05\n",
    "\n",
    "for lr_decay in lr_decays:\n",
    "    param_overrides = {'LR_DECAY_RATE': lr_decay,\n",
    "                       'LR': 0.001,\n",
    "                       'NEPOCH': 30}\n",
    "    mm = mm_mod.ModelManager(hparams=param_overrides, res_name='lr_decay_small_lr.p')\n",
    "    mm.train()\n",
    "    mm.save_results()\n",
    "\n",
    "print(\"Final Validation Acc = %s\" % (mm.validation_acc_history[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just trying a big model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-07 00:24:41,846 __main__     INFO     initialized model with hyperparametrs:\n",
      "2018-10-07 00:24:41,846 __main__     INFO     LR: 0.001\n",
      "2018-10-07 00:24:41,847 __main__     INFO     LR_DECAY_RATE: 0.95\n",
      "2018-10-07 00:24:41,847 __main__     INFO     NEPOCH: 50\n",
      "2018-10-07 00:24:41,847 __main__     INFO     BATCH_SIZE: 32\n",
      "2018-10-07 00:24:41,848 __main__     INFO     NGRAM_SIZE: 4\n",
      "2018-10-07 00:24:41,848 __main__     INFO     VOC_SIZE: 1000000\n",
      "2018-10-07 00:24:41,848 __main__     INFO     EMBEDDING_DIM: 100\n",
      "2018-10-07 00:24:41,849 __main__     INFO     NGRAM_MODE: spacy\n",
      "2018-10-07 00:24:41,849 __main__     INFO     VAL_SIZE: 5000\n",
      "2018-10-07 00:24:41,849 __main__     INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-10-07 00:24:41,849 __main__     INFO     VAL_FREQ: 4\n",
      "2018-10-07 00:24:41,850 __main__     INFO     REMOVE_STOP_WORDS: True\n",
      "2018-10-07 00:24:41,850 __main__     INFO     REMOVE_PUNC: True\n",
      "2018-10-07 00:24:41,850 __main__     INFO     EARLY_STOP: True\n",
      "2018-10-07 00:24:41,850 __main__     INFO     EARLY_STOP_LOOKBACK: 32\n",
      "2018-10-07 00:24:41,851 __main__     INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-10-07 00:24:41,851 __main__     INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-10-07 00:24:41,851 __main__     INFO     looking for the following file paths: ./data/pickles/trainval_spacy_4_True_True.p\n",
      "./data/pickles/test_spacy_4_True_True.p\n",
      "./data/pickles/idx_spacy_4_True_True_5000_1000000.p\n",
      "2018-10-07 00:24:41,854 __main__     INFO     found pickle files in ./data/pickles/, loading them instead of rebuilding ... \n",
      "2018-10-07 00:24:48,388 __main__     INFO     found pickle files for indexer in ./data/pickles/, loading them ... \n",
      "2018-10-07 00:24:48,713 __main__     INFO     setting each dataset's token indexes\n",
      "2018-10-07 00:24:51,311 __main__     INFO     setting each dataset's token indexes\n",
      "2018-10-07 00:25:53,430 __main__     INFO     Epoch: [1/50], Step: [128/625], Val Acc: 50.02, LR: 0.0010\n",
      "2018-10-07 00:26:46,990 __main__     INFO     Epoch: [1/50], Step: [256/625], Val Acc: 58.68, LR: 0.0010\n",
      "2018-10-07 00:27:38,938 __main__     INFO     Epoch: [1/50], Step: [384/625], Val Acc: 73.92, LR: 0.0010\n",
      "2018-10-07 00:28:29,233 __main__     INFO     Epoch: [1/50], Step: [512/625], Val Acc: 67.56, LR: 0.0010\n",
      "2018-10-07 00:30:23,692 __main__     INFO     Epoch: [2/50], Step: [128/625], Val Acc: 77.6, LR: 0.0009\n",
      "2018-10-07 00:31:58,262 __main__     INFO     Epoch: [2/50], Step: [256/625], Val Acc: 72.66, LR: 0.0009\n",
      "2018-10-07 00:33:35,815 __main__     INFO     Epoch: [2/50], Step: [384/625], Val Acc: 82.36, LR: 0.0009\n",
      "2018-10-07 00:34:59,317 __main__     INFO     Epoch: [2/50], Step: [512/625], Val Acc: 80.9, LR: 0.0009\n",
      "2018-10-07 00:37:03,289 __main__     INFO     Epoch: [3/50], Step: [128/625], Val Acc: 84.36, LR: 0.0009\n",
      "2018-10-07 00:38:37,178 __main__     INFO     Epoch: [3/50], Step: [256/625], Val Acc: 85.6, LR: 0.0009\n",
      "2018-10-07 00:40:10,255 __main__     INFO     Epoch: [3/50], Step: [384/625], Val Acc: 86.2, LR: 0.0009\n",
      "2018-10-07 00:41:32,548 __main__     INFO     Epoch: [3/50], Step: [512/625], Val Acc: 85.98, LR: 0.0009\n",
      "2018-10-07 00:43:39,828 __main__     INFO     Epoch: [4/50], Step: [128/625], Val Acc: 86.74, LR: 0.0009\n",
      "2018-10-07 00:45:16,669 __main__     INFO     Epoch: [4/50], Step: [256/625], Val Acc: 87.14, LR: 0.0009\n",
      "2018-10-07 00:46:48,857 __main__     INFO     Epoch: [4/50], Step: [384/625], Val Acc: 86.84, LR: 0.0009\n",
      "2018-10-07 00:48:08,275 __main__     INFO     Epoch: [4/50], Step: [512/625], Val Acc: 87.28, LR: 0.0009\n",
      "2018-10-07 00:50:14,606 __main__     INFO     Epoch: [5/50], Step: [128/625], Val Acc: 87.92, LR: 0.0008\n",
      "2018-10-07 00:51:48,605 __main__     INFO     Epoch: [5/50], Step: [256/625], Val Acc: 87.84, LR: 0.0008\n",
      "2018-10-07 00:53:20,548 __main__     INFO     Epoch: [5/50], Step: [384/625], Val Acc: 88.22, LR: 0.0008\n",
      "2018-10-07 00:54:41,197 __main__     INFO     Epoch: [5/50], Step: [512/625], Val Acc: 88.16, LR: 0.0008\n",
      "2018-10-07 00:56:55,447 __main__     INFO     Epoch: [6/50], Step: [128/625], Val Acc: 88.34, LR: 0.0008\n",
      "2018-10-07 00:58:36,611 __main__     INFO     Epoch: [6/50], Step: [256/625], Val Acc: 88.62, LR: 0.0008\n",
      "2018-10-07 01:00:13,584 __main__     INFO     Epoch: [6/50], Step: [384/625], Val Acc: 88.74, LR: 0.0008\n",
      "2018-10-07 01:01:36,118 __main__     INFO     Epoch: [6/50], Step: [512/625], Val Acc: 88.7, LR: 0.0008\n",
      "2018-10-07 01:03:48,092 __main__     INFO     Epoch: [7/50], Step: [128/625], Val Acc: 88.8, LR: 0.0007\n",
      "2018-10-07 01:05:24,575 __main__     INFO     Epoch: [7/50], Step: [256/625], Val Acc: 88.74, LR: 0.0007\n",
      "2018-10-07 01:06:59,881 __main__     INFO     Epoch: [7/50], Step: [384/625], Val Acc: 89.04, LR: 0.0007\n",
      "2018-10-07 01:08:22,727 __main__     INFO     Epoch: [7/50], Step: [512/625], Val Acc: 89.06, LR: 0.0007\n",
      "2018-10-07 01:10:41,483 __main__     INFO     Epoch: [8/50], Step: [128/625], Val Acc: 89.16, LR: 0.0007\n",
      "2018-10-07 01:12:21,484 __main__     INFO     Epoch: [8/50], Step: [256/625], Val Acc: 89.18, LR: 0.0007\n",
      "2018-10-07 01:14:03,293 __main__     INFO     Epoch: [8/50], Step: [384/625], Val Acc: 89.22, LR: 0.0007\n",
      "2018-10-07 01:15:28,464 __main__     INFO     Epoch: [8/50], Step: [512/625], Val Acc: 89.18, LR: 0.0007\n",
      "2018-10-07 01:17:50,257 __main__     INFO     Epoch: [9/50], Step: [128/625], Val Acc: 89.32, LR: 0.0007\n",
      "2018-10-07 01:19:30,750 __main__     INFO     Epoch: [9/50], Step: [256/625], Val Acc: 89.34, LR: 0.0007\n",
      "2018-10-07 01:21:09,753 __main__     INFO     Epoch: [9/50], Step: [384/625], Val Acc: 89.42, LR: 0.0007\n",
      "2018-10-07 01:22:36,867 __main__     INFO     Epoch: [9/50], Step: [512/625], Val Acc: 89.54, LR: 0.0007\n",
      "2018-10-07 01:24:56,958 __main__     INFO     Epoch: [10/50], Step: [128/625], Val Acc: 89.5, LR: 0.0006\n",
      "2018-10-07 01:26:35,627 __main__     INFO     Epoch: [10/50], Step: [256/625], Val Acc: 89.54, LR: 0.0006\n",
      "2018-10-07 01:28:12,726 __main__     INFO     Epoch: [10/50], Step: [384/625], Val Acc: 89.56, LR: 0.0006\n",
      "2018-10-07 01:29:35,870 __main__     INFO     Epoch: [10/50], Step: [512/625], Val Acc: 89.58, LR: 0.0006\n",
      "2018-10-07 01:32:01,940 __main__     INFO     Epoch: [11/50], Step: [128/625], Val Acc: 89.72, LR: 0.0006\n",
      "2018-10-07 01:33:46,617 __main__     INFO     Epoch: [11/50], Step: [256/625], Val Acc: 89.0, LR: 0.0006\n",
      "2018-10-07 01:35:25,117 __main__     INFO     Epoch: [11/50], Step: [384/625], Val Acc: 89.8, LR: 0.0006\n",
      "2018-10-07 01:36:48,924 __main__     INFO     Epoch: [11/50], Step: [512/625], Val Acc: 89.76, LR: 0.0006\n",
      "2018-10-07 01:39:19,211 __main__     INFO     Epoch: [12/50], Step: [128/625], Val Acc: 89.72, LR: 0.0006\n",
      "2018-10-07 01:41:02,998 __main__     INFO     Epoch: [12/50], Step: [256/625], Val Acc: 89.66, LR: 0.0006\n",
      "2018-10-07 01:42:45,744 __main__     INFO     Epoch: [12/50], Step: [384/625], Val Acc: 89.76, LR: 0.0006\n",
      "2018-10-07 01:44:16,010 __main__     INFO     Epoch: [12/50], Step: [512/625], Val Acc: 89.58, LR: 0.0006\n",
      "2018-10-07 01:46:54,989 __main__     INFO     Epoch: [13/50], Step: [128/625], Val Acc: 89.78, LR: 0.0005\n",
      "2018-10-07 01:48:37,980 __main__     INFO     Epoch: [13/50], Step: [256/625], Val Acc: 89.72, LR: 0.0005\n",
      "2018-10-07 01:50:12,793 __main__     INFO     Epoch: [13/50], Step: [384/625], Val Acc: 89.72, LR: 0.0005\n",
      "2018-10-07 01:51:39,162 __main__     INFO     Epoch: [13/50], Step: [512/625], Val Acc: 89.7, LR: 0.0005\n",
      "2018-10-07 01:54:14,024 __main__     INFO     Epoch: [14/50], Step: [128/625], Val Acc: 89.84, LR: 0.0005\n",
      "2018-10-07 01:56:00,136 __main__     INFO     Epoch: [14/50], Step: [256/625], Val Acc: 89.92, LR: 0.0005\n",
      "2018-10-07 01:57:37,319 __main__     INFO     Epoch: [14/50], Step: [384/625], Val Acc: 89.8, LR: 0.0005\n",
      "2018-10-07 01:59:03,853 __main__     INFO     Epoch: [14/50], Step: [512/625], Val Acc: 89.98, LR: 0.0005\n",
      "2018-10-07 02:01:43,702 __main__     INFO     Epoch: [15/50], Step: [128/625], Val Acc: 89.72, LR: 0.0005\n",
      "2018-10-07 02:03:33,445 __main__     INFO     Epoch: [15/50], Step: [256/625], Val Acc: 89.76, LR: 0.0005\n",
      "2018-10-07 02:05:16,826 __main__     INFO     Epoch: [15/50], Step: [384/625], Val Acc: 89.74, LR: 0.0005\n",
      "2018-10-07 02:06:42,278 __main__     INFO     Epoch: [15/50], Step: [512/625], Val Acc: 89.96, LR: 0.0005\n",
      "2018-10-07 02:09:16,862 __main__     INFO     Epoch: [16/50], Step: [128/625], Val Acc: 89.88, LR: 0.0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-07 02:11:02,861 __main__     INFO     Epoch: [16/50], Step: [256/625], Val Acc: 89.92, LR: 0.0005\n",
      "2018-10-07 02:12:43,511 __main__     INFO     Epoch: [16/50], Step: [384/625], Val Acc: 89.8, LR: 0.0005\n",
      "2018-10-07 02:14:05,518 __main__     INFO     Epoch: [16/50], Step: [512/625], Val Acc: 89.8, LR: 0.0005\n",
      "2018-10-07 02:16:50,899 __main__     INFO     Epoch: [17/50], Step: [128/625], Val Acc: 89.74, LR: 0.0004\n",
      "2018-10-07 02:18:43,499 __main__     INFO     Epoch: [17/50], Step: [256/625], Val Acc: 89.84, LR: 0.0004\n",
      "2018-10-07 02:20:26,374 __main__     INFO     Epoch: [17/50], Step: [384/625], Val Acc: 89.84, LR: 0.0004\n",
      "2018-10-07 02:21:52,655 __main__     INFO     Epoch: [17/50], Step: [512/625], Val Acc: 90.22, LR: 0.0004\n",
      "2018-10-07 02:24:30,486 __main__     INFO     Epoch: [18/50], Step: [128/625], Val Acc: 90.3, LR: 0.0004\n",
      "2018-10-07 02:26:16,930 __main__     INFO     Epoch: [18/50], Step: [256/625], Val Acc: 90.06, LR: 0.0004\n",
      "2018-10-07 02:27:59,708 __main__     INFO     Epoch: [18/50], Step: [384/625], Val Acc: 89.76, LR: 0.0004\n",
      "2018-10-07 02:29:28,864 __main__     INFO     Epoch: [18/50], Step: [512/625], Val Acc: 90.24, LR: 0.0004\n",
      "2018-10-07 02:32:17,265 __main__     INFO     Epoch: [19/50], Step: [128/625], Val Acc: 90.36, LR: 0.0004\n",
      "2018-10-07 02:34:04,988 __main__     INFO     Epoch: [19/50], Step: [256/625], Val Acc: 90.18, LR: 0.0004\n",
      "2018-10-07 02:35:46,469 __main__     INFO     Epoch: [19/50], Step: [384/625], Val Acc: 89.86, LR: 0.0004\n",
      "2018-10-07 02:37:10,283 __main__     INFO     Epoch: [19/50], Step: [512/625], Val Acc: 89.86, LR: 0.0004\n",
      "2018-10-07 02:39:53,864 __main__     INFO     Epoch: [20/50], Step: [128/625], Val Acc: 89.84, LR: 0.0004\n",
      "2018-10-07 02:41:45,155 __main__     INFO     Epoch: [20/50], Step: [256/625], Val Acc: 90.24, LR: 0.0004\n",
      "2018-10-07 02:43:33,676 __main__     INFO     Epoch: [20/50], Step: [384/625], Val Acc: 90.3, LR: 0.0004\n",
      "2018-10-07 02:45:07,824 __main__     INFO     Epoch: [20/50], Step: [512/625], Val Acc: 90.28, LR: 0.0004\n",
      "2018-10-07 02:47:53,328 __main__     INFO     Epoch: [21/50], Step: [128/625], Val Acc: 89.96, LR: 0.0004\n",
      "2018-10-07 02:49:42,148 __main__     INFO     Epoch: [21/50], Step: [256/625], Val Acc: 90.2, LR: 0.0004\n",
      "2018-10-07 02:51:26,476 __main__     INFO     Epoch: [21/50], Step: [384/625], Val Acc: 90.26, LR: 0.0004\n",
      "2018-10-07 02:52:53,796 __main__     INFO     Epoch: [21/50], Step: [512/625], Val Acc: 90.28, LR: 0.0004\n",
      "2018-10-07 02:55:41,960 __main__     INFO     Epoch: [22/50], Step: [128/625], Val Acc: 90.0, LR: 0.0003\n",
      "2018-10-07 02:57:29,635 __main__     INFO     Epoch: [22/50], Step: [256/625], Val Acc: 90.24, LR: 0.0003\n",
      "2018-10-07 02:59:19,248 __main__     INFO     Epoch: [22/50], Step: [384/625], Val Acc: 90.16, LR: 0.0003\n",
      "2018-10-07 03:00:53,583 __main__     INFO     Epoch: [22/50], Step: [512/625], Val Acc: 90.08, LR: 0.0003\n",
      "2018-10-07 03:03:37,436 __main__     INFO     Epoch: [23/50], Step: [128/625], Val Acc: 90.18, LR: 0.0003\n",
      "2018-10-07 03:05:22,249 __main__     INFO     Epoch: [23/50], Step: [256/625], Val Acc: 90.1, LR: 0.0003\n",
      "2018-10-07 03:07:01,519 __main__     INFO     Epoch: [23/50], Step: [384/625], Val Acc: 90.04, LR: 0.0003\n",
      "2018-10-07 03:08:28,385 __main__     INFO     Epoch: [23/50], Step: [512/625], Val Acc: 90.22, LR: 0.0003\n",
      "2018-10-07 03:11:27,585 __main__     INFO     Epoch: [24/50], Step: [128/625], Val Acc: 90.1, LR: 0.0003\n",
      "2018-10-07 03:13:13,721 __main__     INFO     Epoch: [24/50], Step: [256/625], Val Acc: 90.16, LR: 0.0003\n",
      "2018-10-07 03:14:54,056 __main__     INFO     Epoch: [24/50], Step: [384/625], Val Acc: 90.08, LR: 0.0003\n",
      "2018-10-07 03:16:21,016 __main__     INFO     Epoch: [24/50], Step: [512/625], Val Acc: 90.24, LR: 0.0003\n",
      "2018-10-07 03:19:21,386 __main__     INFO     Epoch: [25/50], Step: [128/625], Val Acc: 90.14, LR: 0.0003\n",
      "2018-10-07 03:21:17,640 __main__     INFO     Epoch: [25/50], Step: [256/625], Val Acc: 90.1, LR: 0.0003\n",
      "2018-10-07 03:23:07,304 __main__     INFO     Epoch: [25/50], Step: [384/625], Val Acc: 90.28, LR: 0.0003\n",
      "2018-10-07 03:24:36,655 __main__     INFO     Epoch: [25/50], Step: [512/625], Val Acc: 90.12, LR: 0.0003\n",
      "2018-10-07 03:27:29,145 __main__     INFO     Epoch: [26/50], Step: [128/625], Val Acc: 90.18, LR: 0.0003\n",
      "2018-10-07 03:29:18,387 __main__     INFO     Epoch: [26/50], Step: [256/625], Val Acc: 90.22, LR: 0.0003\n",
      "2018-10-07 03:31:03,528 __main__     INFO     Epoch: [26/50], Step: [384/625], Val Acc: 90.16, LR: 0.0003\n",
      "2018-10-07 03:32:36,886 __main__     INFO     Epoch: [26/50], Step: [512/625], Val Acc: 90.2, LR: 0.0003\n",
      "2018-10-07 03:35:38,037 __main__     INFO     Epoch: [27/50], Step: [128/625], Val Acc: 90.24, LR: 0.0003\n",
      "2018-10-07 03:35:38,037 __main__     INFO     --- earily stop triggered ---\n",
      "2018-10-07 03:35:38,038 __main__     INFO     generating new pandas dataframe to store results\n",
      "Final Validation Acc = 90.24 (train time: 11456.2s)\n",
      "\n",
      "time: 3h 10min 56s\n"
     ]
    }
   ],
   "source": [
    "reload(mm_mod)\n",
    "logger.setLevel(logging.INFO)\n",
    "start_time = time.time()\n",
    "param_overrides = {'NEPOCH': 50,\n",
    "                   'LR': 0.001,\n",
    "                   'LR_DECAY_RATE': 0.95,\n",
    "                   'VOC_SIZE': 1000000,\n",
    "                   'NGRAM_SIZE': 4,\n",
    "                   'NGRAM_MODE':'spacy',\n",
    "                   'EMBEDDING_DIM':100,\n",
    "                   'EARLY_STOP_LOOKBACK': 32}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='experiment.p')\n",
    "mm.train()\n",
    "print(\"Final Validation Acc = %s (train time: %.1fs)\\n\" % (mm.validation_acc_history[-1], \n",
    "                                                      time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "torch.save(mm.model, r'model_state.st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
