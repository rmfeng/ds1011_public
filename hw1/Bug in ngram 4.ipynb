{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ModelManager as mm_mod\n",
    "import config_defaults as cd\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-02 22:11:57,833 __main__     INFO     initialized model with hyperparametrs:\n",
      "2018-10-02 22:11:57,833 __main__     INFO     LR: 0.01\n",
      "2018-10-02 22:11:57,834 __main__     INFO     NEPOCH: 10\n",
      "2018-10-02 22:11:57,834 __main__     INFO     BATCH_SIZE: 32\n",
      "2018-10-02 22:11:57,834 __main__     INFO     NGRAM_SIZE: 4\n",
      "2018-10-02 22:11:57,835 __main__     INFO     VOC_SIZE: 10000\n",
      "2018-10-02 22:11:57,835 __main__     INFO     EMBEDDING_DIM: 100\n",
      "2018-10-02 22:11:57,836 __main__     INFO     NGRAM_MODE: naive\n",
      "2018-10-02 22:11:57,836 __main__     INFO     VAL_SIZE: 5000\n",
      "2018-10-02 22:11:57,837 __main__     INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "2018-10-02 22:11:57,837 __main__     INFO     VAL_FREQ: 4\n",
      "2018-10-02 22:11:57,838 __main__     INFO     REMOVE_STOP_WORDS: True\n",
      "2018-10-02 22:11:57,838 __main__     INFO     REMOVE_PUNC: True\n",
      "2018-10-02 22:11:57,839 __main__     INFO     EARLY_STOP: True\n",
      "2018-10-02 22:11:57,839 __main__     INFO     EARLY_STOP_LOOKBACK: 2\n",
      "2018-10-02 22:11:57,839 __main__     INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "2018-10-02 22:11:57,840 __main__     INFO     allow pickle loads: True, allow pickle saves: True\n",
      "2018-10-02 22:11:57,840 __main__     INFO     found pickle files in ./data/pickles/, loading them instead of rebuilding ... \n",
      "2018-10-02 22:12:04,153 __main__     INFO     constructing ngram_indexer ...\n",
      "2018-10-02 22:12:04,158 __main__     INFO     indexer length 20000\n",
      "2018-10-02 22:12:09,065 __main__     INFO     final vocal size: 10002\n",
      "2018-10-02 22:12:09,065 __main__     INFO     setting each dataset's token indexes\n",
      "2018-10-02 22:12:10,010 __main__     INFO     setting each dataset's token indexes\n",
      "time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "reload(mm_mod)\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(logging.INFO)\n",
    "param_overrides = {'NGRAM_MODE': 'naive',\n",
    "                   'NGRAM_SIZE': 4,\n",
    "                   'VOC_SIZE': 10000}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='vocab_explore.p')\n",
    "mm.load_data()\n",
    "mm.data_to_pipe()\n",
    "mm.model_init()  # make sure we force the model to re-init\n",
    "# mm.training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 599 µs\n"
     ]
    }
   ],
   "source": [
    "import data_processor as dp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as tfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.37 ms\n"
     ]
    }
   ],
   "source": [
    "imdb_train = dp.IMDBDataset(mm.data['train'])\n",
    "imdb_validation = dp.IMDBDataset(mm.data['val'])\n",
    "imdb_test = dp.IMDBDataset(mm.data['test'])\n",
    "\n",
    "train_loader = DataLoader(dataset=imdb_train,\n",
    "                                   batch_size=mm.hparams['BATCH_SIZE'],\n",
    "                                   collate_fn=dp.imdb_collate_func,\n",
    "                                   shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(dataset=imdb_validation,\n",
    "                                 batch_size=mm.hparams['BATCH_SIZE'],\n",
    "                                 collate_fn=dp.imdb_collate_func,\n",
    "                                 shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=imdb_test,\n",
    "                                  batch_size=mm.hparams['BATCH_SIZE'],\n",
    "                                  collate_fn=dp.imdb_collate_func,\n",
    "                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 740 µs\n"
     ]
    }
   ],
   "source": [
    "op_constr = mm.hparams['OPTIMIZER']\n",
    "optimizer = op_constr(mm.model.parameters(), lr=mm.hparams['LR'])\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': 0.01,\n",
       " 'NEPOCH': 10,\n",
       " 'BATCH_SIZE': 32,\n",
       " 'NGRAM_SIZE': 4,\n",
       " 'VOC_SIZE': 10000,\n",
       " 'EMBEDDING_DIM': 100,\n",
       " 'NGRAM_MODE': 'naive',\n",
       " 'VAL_SIZE': 5000,\n",
       " 'OPTIMIZER': torch.optim.adam.Adam,\n",
       " 'VAL_FREQ': 4,\n",
       " 'REMOVE_STOP_WORDS': True,\n",
       " 'REMOVE_PUNC': True,\n",
       " 'EARLY_STOP': True,\n",
       " 'EARLY_STOP_LOOKBACK': 2,\n",
       " 'EARLY_STOP_MIN_IMPROVE': 0.01}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.6 ms\n"
     ]
    }
   ],
   "source": [
    "mm.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.89 ms\n"
     ]
    }
   ],
   "source": [
    "import BagOfWords as BoW\n",
    "model = BoW.BagOfWords(len(mm.data['vocab']), mm.hparams['EMBEDDING_DIM']).to(cd.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2214,    1,    1, ...,    0,    0,    0]), array([28,  1,  1, ...,  0,  0,  0]), array([   8, 1518,    1, ...,    0,    0,    0]), array([304,   1,   1, ...,   0,   0,   0]), array([2190,    1,    1, ...,    0,    0,    0]), array([1, 1, 1, ..., 0, 0, 0]), array([1, 1, 1, ..., 0, 0, 0]), array([  40, 5525,    1, ...,    0,    0,    0]), array([1, 1, 1, ..., 0, 0, 0]), array([1980,    1,    1, ...,    0,    0,    0]), array([2728,    1,    1, ...,    0,    0,    0]), array([195,   1,   1, ...,   0,   0,   0]), array([122,   1,   1, ...,   0,   0,   0]), array([5093,    1,    1, ...,    0,    0,    0]), array([1391,    1,    1, ...,    0,    0,    0]), array([0., 0., 0., ..., 0., 0., 0.]), array([6581,    1,    1, ...,    0,    0,    0]), array([ 70, 991,   1, ...,   0,   0,   0]), array([1, 1, 1, ..., 0, 0, 0]), array([1, 1, 1, ..., 0, 0, 0]), array([603,   1,   1, ...,   0,   0,   0]), array([1, 1, 1, ..., 0, 0, 0]), array([782,   1,   1, ...,   0,   0,   0]), array([1, 1, 1, ..., 1, 1, 1]), array([15,  1,  1, ...,  0,  0,  0]), array([1149,    1,    1, ...,    0,    0,    0]), array([6701,    1,    1, ...,    0,    0,    0]), array([1678,    1,    1, ...,    0,    0,    0]), array([  70, 1676,    1, ...,    0,    0,    0]), array([1, 1, 1, ..., 0, 0, 0]), array([1, 1, 1, ..., 0, 0, 0]), array([ 70, 991,   1, ...,   0,   0,   0])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got CPUDoubleTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9fb56fb1abef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GradSchool/nlpDS1011/ds1011/hw1/BagOfWords.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, length)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    108\u001b[0m         return F.embedding(\n\u001b[1;32m    109\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got CPUDoubleTensor instead (while checking arguments for embedding)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.72 ms\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.21 ms\n"
     ]
    }
   ],
   "source": [
    "nparr = pkl.load(open(r'./results/nparr.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.79 ms\n"
     ]
    }
   ],
   "source": [
    "nparr[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figuring out which one is the all 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 413 µs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 399 µs\n"
     ]
    }
   ],
   "source": [
    "check_data = imdb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/neg/10962_3.txt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/neg/2331_1.txt</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/neg/874_1.txt</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/pos/4518_9.txt</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/neg/9122_1.txt</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      count\n",
       "./data/aclImdb/train/neg/10962_3.txt      0\n",
       "./data/aclImdb/train/neg/2331_1.txt       2\n",
       "./data/aclImdb/train/neg/874_1.txt        3\n",
       "./data/aclImdb/train/pos/4518_9.txt       3\n",
       "./data/aclImdb/train/neg/9122_1.txt       4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "debug_dict = {}\n",
    "for i, data in enumerate(imdb_train.data_list):\n",
    "    debug_dict[data.file_name] = len(np.unique(np.array(data.token_idx)))\n",
    "    \n",
    "df = pd.DataFrame(debug_dict, index=['count']).T\n",
    "df.sort_values('count').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/neg/10962_3.txt</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/neg/2331_1.txt</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/pos/4518_9.txt</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/neg/874_1.txt</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./data/aclImdb/train/pos/3247_10.txt</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      count\n",
       "./data/aclImdb/train/neg/10962_3.txt     52\n",
       "./data/aclImdb/train/neg/2331_1.txt      53\n",
       "./data/aclImdb/train/pos/4518_9.txt      70\n",
       "./data/aclImdb/train/neg/874_1.txt       80\n",
       "./data/aclImdb/train/pos/3247_10.txt     81"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 688 ms\n"
     ]
    }
   ],
   "source": [
    "debug_dict = {}\n",
    "for i, data in enumerate(imdb_train.data_list):\n",
    "    debug_dict[data.file_name] = len(data.raw_text)\n",
    "    if data.file_name == './data/aclImdb/train/neg/10962_3.txt':\n",
    "        err_data = data\n",
    "    \n",
    "df = pd.DataFrame(debug_dict, index=['count']).T\n",
    "df.sort_values('count').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this movie is terrible but it has some good effects.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.24 ms\n"
     ]
    }
   ],
   "source": [
    "err_data.raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.05 ms\n"
     ]
    }
   ],
   "source": [
    "err_data.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.72 ms\n"
     ]
    }
   ],
   "source": [
    "from ngrams import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 473 µs\n"
     ]
    }
   ],
   "source": [
    "dataset = tokenize(err_data.raw_text, mode='naive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.38 s\n"
     ]
    }
   ],
   "source": [
    "pickle_path_train_val = r'./data/pickles/trainval_4_naive_True_True.p'\n",
    "train_and_val_data = pkl.load(open(pickle_path_train_val, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.66 ms\n"
     ]
    }
   ],
   "source": [
    "import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-02 22:34:02,466 __main__     INFO     constructing ngram_indexer ...\n",
      "2018-10-02 22:34:02,473 __main__     INFO     indexer length 20000\n",
      "2018-10-02 22:34:07,426 __main__     INFO     final vocal size: 10002\n",
      "time: 4.96 s\n"
     ]
    }
   ],
   "source": [
    "train_ngram_indexer, ngram_counter = ngrams.create_ngram_indexer(train_and_val_data,\n",
    "                                                                 topk=mm.hparams['VOC_SIZE'],\n",
    "                                                                 val_size=mm.hparams['VAL_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.28 ms\n"
     ]
    }
   ],
   "source": [
    "len(train_ngram_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie', 'terrible', 'good', 'effects.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Counter(), [])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.56 ms\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "from collections import Counter\n",
    "\n",
    "tokens = tokenize(err_data.raw_text, mode='naive')\n",
    "print(tokens)\n",
    "\n",
    "all_ngrams = []\n",
    "for i in range(0, len(tokens) - n):\n",
    "    for j in range(1, n + 1):\n",
    "        print('calling methods for j=%s, i = %s' % (j, i))\n",
    "        all_ngrams.append(get_n_gram_at_position_i(j, i, tokens))\n",
    "ngram_counter = Counter(all_ngrams)\n",
    "\n",
    "ngram_counter, all_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 553 µs\n"
     ]
    }
   ],
   "source": [
    "tokens2 = tokenize(data.raw_text, mode='naive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.3 ms\n"
     ]
    }
   ],
   "source": [
    "def extract_ngram_from_text(text, n, remove_stopwords=True, remove_punc=True, mode='spacy'):\n",
    "    \"\"\"\n",
    "    Function that retrieves all n-grams from the input string\n",
    "    :param text: raw string\n",
    "    :param n: integer that tells the model to retrieve all k-gram where k<=n\n",
    "    :param remove_stopwords: whether or not to remove stopwords from lib\n",
    "    :param remove_punc: whether or not to remove punctuation from lib\n",
    "    :param mode: {'spacy', 'naive'}\n",
    "    :return ngram_counter: a counter that maps n-gram to its frequency\n",
    "    :return tokens: a list of parsed ngrams\n",
    "    \"\"\"\n",
    "    tokens = tokenize(text, remove_stopwords=remove_stopwords, remove_punc=remove_punc, mode=mode)\n",
    "    all_ngrams = []\n",
    "    for i in range(0, len(tokens)):\n",
    "        all_ngrams.append(get_n_gram_at_position_i(i, n, tokens))\n",
    "    ngram_counter = Counter(all_ngrams)\n",
    "    return ngram_counter, all_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-103-b89974563ccc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-103-b89974563ccc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def get_n_gram_at_position_i(i, n, tokens):\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.69 ms\n"
     ]
    }
   ],
   "source": [
    "def get_n_gram_at_position_i(i, n, tokens):\n",
    "    \"\"\" returns list of all n grams at position i\"\"\"\n",
    "    if i + n < len(tokens):\n",
    "        # can look forward n and be okay\n",
    "        sub_tokens = tokens[i:i + n]\n",
    "    else\n",
    "        sub_tokens = tokens[i:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie', 'terrible', 'good', 'effects.']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.48 ms\n"
     ]
    }
   ],
   "source": [
    "tokens[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 576 µs\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "def findsubsets(S,m):\n",
    "    return set(itertools.combinations(S, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 416 µs\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams as nltk_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie',), ('terrible',), ('good',), ('effects.',)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.36 ms\n"
     ]
    }
   ],
   "source": [
    "list(ngrams(tokens,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
