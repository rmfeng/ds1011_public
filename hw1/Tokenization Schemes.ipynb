{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ModelManager as mm_mod\n",
    "import config_defaults as cd\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "import torch\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     initialized model with hyperparametrs:\n",
      "INFO     LR: 0.01\n",
      "INFO     LR_DECAY_RATE: 0.95\n",
      "INFO     NEPOCH: 10\n",
      "INFO     BATCH_SIZE: 32\n",
      "INFO     NGRAM_SIZE: 4\n",
      "INFO     VOC_SIZE: 100000\n",
      "INFO     EMBEDDING_DIM: 50\n",
      "INFO     NGRAM_MODE: naive\n",
      "INFO     VAL_SIZE: 5000\n",
      "INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "INFO     VAL_FREQ: 4\n",
      "INFO     REMOVE_STOP_WORDS: True\n",
      "INFO     REMOVE_PUNC: False\n",
      "INFO     EARLY_STOP: True\n",
      "INFO     EARLY_STOP_LOOKBACK: 8\n",
      "INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "INFO     allow pickle loads: True, allow pickle saves: True\n",
      "INFO     Starting Training on device: cuda:0\n",
      "INFO     looking for the following file paths: ./data/pickles/trainval_naive_4_False_True.p\n",
      "./data/pickles/test_naive_4_False_True.p\n",
      "./data/pickles/idx_naive_4_False_True_5000_100000.p\n",
      "INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "INFO     loading datasets ...\n",
      "INFO     extracting ngram from training and val set of size 25000...\n",
      "INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ba11a15911470b90b6359c30b282b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     extracting ngram from test set of size 25000 ...\n",
      "INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806bd4ee3c5b4ff1b5cf1f10c0ad1089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     saving pickled data to folder ./data/pickles/ ...\n",
      "INFO     constructing ngram_indexer ...\n",
      "INFO     indexer length 20000\n",
      "INFO     final vocal size: 100002\n",
      "INFO     saving pickled indexer to folder ./data/pickles/ ...\n",
      "INFO     setting each dataset's token indexes\n",
      "INFO     setting each dataset's token indexes\n",
      "INFO     Ep: [1/10], Sp: [128/625], VAcc: 70.42, VLoss: 101.9, TAcc: 73.685, TLoss: 401.6, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [256/625], VAcc: 83.98, VLoss: 83.2, TAcc: 87.285, TLoss: 316.1, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [384/625], VAcc: 87.02, VLoss: 75.6, TAcc: 91.615, TLoss: 277.0, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [512/625], VAcc: 88.16, VLoss: 72.5, TAcc: 94.055, TLoss: 257.2, LR: 0.0100\n",
      "INFO     Ep: [2/10], Sp: [128/625], VAcc: 89.08, VLoss: 69.6, TAcc: 96.75, TLoss: 235.0, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [256/625], VAcc: 88.74, VLoss: 69.4, TAcc: 97.015, TLoss: 229.9, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [384/625], VAcc: 87.02, VLoss: 69.8, TAcc: 97.35, TLoss: 225.5, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [512/625], VAcc: 87.68, VLoss: 69.3, TAcc: 98.17, TLoss: 219.5, LR: 0.0095\n",
      "INFO     Ep: [3/10], Sp: [128/625], VAcc: 89.6, VLoss: 66.8, TAcc: 99.59, TLoss: 206.6, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [256/625], VAcc: 89.58, VLoss: 66.8, TAcc: 99.62, TLoss: 205.3, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [384/625], VAcc: 89.44, VLoss: 66.5, TAcc: 99.74, TLoss: 203.1, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [512/625], VAcc: 88.76, VLoss: 66.7, TAcc: 99.85, TLoss: 201.4, LR: 0.0090\n",
      "INFO     Ep: [4/10], Sp: [128/625], VAcc: 89.18, VLoss: 66.1, TAcc: 99.99, TLoss: 198.9, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [256/625], VAcc: 88.78, VLoss: 66.3, TAcc: 99.99, TLoss: 198.6, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [384/625], VAcc: 89.56, VLoss: 65.7, TAcc: 100.0, TLoss: 198.0, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [512/625], VAcc: 89.28, VLoss: 65.7, TAcc: 100.0, TLoss: 197.6, LR: 0.0086\n",
      "INFO     Ep: [5/10], Sp: [128/625], VAcc: 89.58, VLoss: 65.6, TAcc: 100.0, TLoss: 197.1, LR: 0.0081\n",
      "INFO     --- earily stop triggered ---\n",
      "INFO     generating new pandas dataframe to store results\n",
      "INFO     results saved to ./results/tokenization.p\n",
      "time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "param_overrides={\n",
    "    'REMOVE_STOP_WORDS': True,\n",
    "    'REMOVE_PUNC': False,\n",
    "    'NGRAM_MODE': 'naive'\n",
    "}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='tokenization.p')\n",
    "mm.train()\n",
    "mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     initialized model with hyperparametrs:\n",
      "INFO     LR: 0.01\n",
      "INFO     LR_DECAY_RATE: 0.95\n",
      "INFO     NEPOCH: 10\n",
      "INFO     BATCH_SIZE: 32\n",
      "INFO     NGRAM_SIZE: 4\n",
      "INFO     VOC_SIZE: 100000\n",
      "INFO     EMBEDDING_DIM: 50\n",
      "INFO     NGRAM_MODE: naive\n",
      "INFO     VAL_SIZE: 5000\n",
      "INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "INFO     VAL_FREQ: 4\n",
      "INFO     REMOVE_STOP_WORDS: False\n",
      "INFO     REMOVE_PUNC: True\n",
      "INFO     EARLY_STOP: True\n",
      "INFO     EARLY_STOP_LOOKBACK: 8\n",
      "INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "INFO     allow pickle loads: True, allow pickle saves: True\n",
      "INFO     Starting Training on device: cuda:0\n",
      "INFO     looking for the following file paths: ./data/pickles/trainval_naive_4_True_False.p\n",
      "./data/pickles/test_naive_4_True_False.p\n",
      "./data/pickles/idx_naive_4_True_False_5000_100000.p\n",
      "INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "INFO     loading datasets ...\n",
      "INFO     extracting ngram from training and val set of size 25000...\n",
      "INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221817a2cfe644589f316b6252967ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     extracting ngram from test set of size 25000 ...\n",
      "INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5780c2a98ac94d368156f0af3c7407d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     saving pickled data to folder ./data/pickles/ ...\n",
      "INFO     constructing ngram_indexer ...\n",
      "INFO     indexer length 20000\n",
      "INFO     final vocal size: 100002\n",
      "INFO     saving pickled indexer to folder ./data/pickles/ ...\n",
      "INFO     setting each dataset's token indexes\n",
      "INFO     setting each dataset's token indexes\n",
      "INFO     Ep: [1/10], Sp: [128/625], VAcc: 77.62, VLoss: 98.9, TAcc: 80.53, TLoss: 388.9, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [256/625], VAcc: 82.56, VLoss: 82.8, TAcc: 86.97, TLoss: 313.0, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [384/625], VAcc: 85.04, VLoss: 76.3, TAcc: 90.92, TLoss: 278.8, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [512/625], VAcc: 87.68, VLoss: 72.5, TAcc: 93.875, TLoss: 258.6, LR: 0.0100\n",
      "INFO     Ep: [2/10], Sp: [128/625], VAcc: 88.86, VLoss: 69.3, TAcc: 96.595, TLoss: 235.6, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [256/625], VAcc: 87.4, VLoss: 69.8, TAcc: 96.525, TLoss: 231.9, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [384/625], VAcc: 89.14, VLoss: 67.7, TAcc: 97.93, TLoss: 221.4, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [512/625], VAcc: 89.76, VLoss: 66.9, TAcc: 98.83, TLoss: 215.5, LR: 0.0095\n",
      "INFO     Ep: [3/10], Sp: [128/625], VAcc: 89.78, VLoss: 66.0, TAcc: 99.61, TLoss: 207.6, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [256/625], VAcc: 89.82, VLoss: 65.9, TAcc: 99.675, TLoss: 205.4, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [384/625], VAcc: 89.8, VLoss: 65.8, TAcc: 99.785, TLoss: 203.4, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [512/625], VAcc: 89.84, VLoss: 65.5, TAcc: 99.885, TLoss: 201.6, LR: 0.0090\n",
      "INFO     Ep: [4/10], Sp: [128/625], VAcc: 90.0, VLoss: 65.2, TAcc: 99.99, TLoss: 199.4, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [256/625], VAcc: 89.88, VLoss: 65.1, TAcc: 99.99, TLoss: 198.8, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [384/625], VAcc: 89.9, VLoss: 65.0, TAcc: 99.99, TLoss: 198.4, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [512/625], VAcc: 89.84, VLoss: 65.0, TAcc: 99.995, TLoss: 198.2, LR: 0.0086\n",
      "INFO     Ep: [5/10], Sp: [128/625], VAcc: 89.8, VLoss: 64.8, TAcc: 100.0, TLoss: 197.4, LR: 0.0081\n",
      "INFO     Ep: [5/10], Sp: [256/625], VAcc: 89.86, VLoss: 64.8, TAcc: 100.0, TLoss: 197.2, LR: 0.0081\n",
      "INFO     Ep: [5/10], Sp: [384/625], VAcc: 89.68, VLoss: 64.8, TAcc: 100.0, TLoss: 197.0, LR: 0.0081\n",
      "INFO     Ep: [5/10], Sp: [512/625], VAcc: 89.82, VLoss: 64.8, TAcc: 100.0, TLoss: 196.9, LR: 0.0081\n",
      "INFO     Ep: [6/10], Sp: [128/625], VAcc: 89.7, VLoss: 64.9, TAcc: 100.0, TLoss: 196.7, LR: 0.0077\n",
      "INFO     --- earily stop triggered ---\n",
      "INFO     found historical file, loading the dataframe at ./results/tokenization.p\n",
      "INFO     results saved to ./results/tokenization.p\n",
      "time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "param_overrides={\n",
    "    'REMOVE_STOP_WORDS': False,\n",
    "    'REMOVE_PUNC': True,\n",
    "    'NGRAM_MODE': 'naive'\n",
    "}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='tokenization.p')\n",
    "mm.train()\n",
    "mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     initialized model with hyperparametrs:\n",
      "INFO     LR: 0.01\n",
      "INFO     LR_DECAY_RATE: 0.95\n",
      "INFO     NEPOCH: 10\n",
      "INFO     BATCH_SIZE: 32\n",
      "INFO     NGRAM_SIZE: 4\n",
      "INFO     VOC_SIZE: 100000\n",
      "INFO     EMBEDDING_DIM: 50\n",
      "INFO     NGRAM_MODE: naive\n",
      "INFO     VAL_SIZE: 5000\n",
      "INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "INFO     VAL_FREQ: 4\n",
      "INFO     REMOVE_STOP_WORDS: False\n",
      "INFO     REMOVE_PUNC: False\n",
      "INFO     EARLY_STOP: True\n",
      "INFO     EARLY_STOP_LOOKBACK: 8\n",
      "INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "INFO     allow pickle loads: True, allow pickle saves: True\n",
      "INFO     Starting Training on device: cuda:0\n",
      "INFO     looking for the following file paths: ./data/pickles/trainval_naive_4_False_False.p\n",
      "./data/pickles/test_naive_4_False_False.p\n",
      "./data/pickles/idx_naive_4_False_False_5000_100000.p\n",
      "INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "INFO     loading datasets ...\n",
      "INFO     extracting ngram from training and val set of size 25000...\n",
      "INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107db1cc912f4ab59e4e0b4aee966130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     extracting ngram from test set of size 25000 ...\n",
      "INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d51bcc25ad42178a2abd2ab222ab80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     saving pickled data to folder ./data/pickles/ ...\n",
      "INFO     constructing ngram_indexer ...\n",
      "INFO     indexer length 20000\n",
      "INFO     final vocal size: 100002\n",
      "INFO     saving pickled indexer to folder ./data/pickles/ ...\n",
      "INFO     setting each dataset's token indexes\n",
      "INFO     setting each dataset's token indexes\n",
      "INFO     Ep: [1/10], Sp: [128/625], VAcc: 80.22, VLoss: 99.7, TAcc: 82.76, TLoss: 392.7, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [256/625], VAcc: 83.82, VLoss: 81.5, TAcc: 87.68, TLoss: 307.9, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [384/625], VAcc: 85.94, VLoss: 75.4, TAcc: 92.0, TLoss: 274.6, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [512/625], VAcc: 86.92, VLoss: 72.8, TAcc: 93.935, TLoss: 257.1, LR: 0.0100\n",
      "INFO     Ep: [2/10], Sp: [128/625], VAcc: 88.84, VLoss: 68.9, TAcc: 96.535, TLoss: 233.7, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [256/625], VAcc: 87.24, VLoss: 69.6, TAcc: 96.66, TLoss: 230.2, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [384/625], VAcc: 89.06, VLoss: 67.5, TAcc: 98.105, TLoss: 220.3, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [512/625], VAcc: 88.92, VLoss: 67.3, TAcc: 98.81, TLoss: 214.8, LR: 0.0095\n",
      "INFO     Ep: [3/10], Sp: [128/625], VAcc: 89.64, VLoss: 66.3, TAcc: 99.71, TLoss: 206.9, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [256/625], VAcc: 89.56, VLoss: 65.9, TAcc: 99.76, TLoss: 204.7, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [384/625], VAcc: 89.12, VLoss: 66.2, TAcc: 99.775, TLoss: 203.5, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [512/625], VAcc: 89.72, VLoss: 65.5, TAcc: 99.88, TLoss: 201.2, LR: 0.0090\n",
      "INFO     Ep: [4/10], Sp: [128/625], VAcc: 89.8, VLoss: 65.3, TAcc: 99.97, TLoss: 199.1, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [256/625], VAcc: 89.72, VLoss: 65.2, TAcc: 99.975, TLoss: 198.7, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [384/625], VAcc: 89.62, VLoss: 65.2, TAcc: 99.99, TLoss: 198.6, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [512/625], VAcc: 89.38, VLoss: 65.5, TAcc: 99.98, TLoss: 198.0, LR: 0.0086\n",
      "INFO     Ep: [5/10], Sp: [128/625], VAcc: 89.68, VLoss: 65.1, TAcc: 100.0, TLoss: 197.2, LR: 0.0081\n",
      "INFO     Ep: [5/10], Sp: [256/625], VAcc: 89.64, VLoss: 64.9, TAcc: 100.0, TLoss: 197.1, LR: 0.0081\n",
      "INFO     Ep: [5/10], Sp: [384/625], VAcc: 89.74, VLoss: 65.0, TAcc: 100.0, TLoss: 196.9, LR: 0.0081\n",
      "INFO     Ep: [5/10], Sp: [512/625], VAcc: 89.66, VLoss: 64.8, TAcc: 100.0, TLoss: 196.7, LR: 0.0081\n",
      "INFO     Ep: [6/10], Sp: [128/625], VAcc: 89.76, VLoss: 64.9, TAcc: 100.0, TLoss: 196.6, LR: 0.0077\n",
      "INFO     --- earily stop triggered ---\n",
      "INFO     found historical file, loading the dataframe at ./results/tokenization.p\n",
      "INFO     results saved to ./results/tokenization.p\n",
      "time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "param_overrides={\n",
    "    'REMOVE_STOP_WORDS': False,\n",
    "    'REMOVE_PUNC': False,\n",
    "    'NGRAM_MODE': 'naive'\n",
    "}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='tokenization.p')\n",
    "mm.train()\n",
    "mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     initialized model with hyperparametrs:\n",
      "INFO     LR: 0.01\n",
      "INFO     LR_DECAY_RATE: 0.95\n",
      "INFO     NEPOCH: 10\n",
      "INFO     BATCH_SIZE: 32\n",
      "INFO     NGRAM_SIZE: 4\n",
      "INFO     VOC_SIZE: 100000\n",
      "INFO     EMBEDDING_DIM: 50\n",
      "INFO     NGRAM_MODE: naive\n",
      "INFO     VAL_SIZE: 5000\n",
      "INFO     OPTIMIZER: <class 'torch.optim.adam.Adam'>\n",
      "INFO     VAL_FREQ: 4\n",
      "INFO     REMOVE_STOP_WORDS: True\n",
      "INFO     REMOVE_PUNC: True\n",
      "INFO     EARLY_STOP: True\n",
      "INFO     EARLY_STOP_LOOKBACK: 8\n",
      "INFO     EARLY_STOP_MIN_IMPROVE: 0.01\n",
      "INFO     allow pickle loads: True, allow pickle saves: True\n",
      "INFO     Starting Training on device: cuda:0\n",
      "INFO     looking for the following file paths: ./data/pickles/trainval_naive_4_True_True.p\n",
      "./data/pickles/test_naive_4_True_True.p\n",
      "./data/pickles/idx_naive_4_True_True_5000_100000.p\n",
      "INFO     did not find pickle files in ./data/pickles/, rebuilding ...\n",
      "INFO     loading datasets ...\n",
      "INFO     extracting ngram from training and val set of size 25000...\n",
      "INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b71c1729bb84388b41c0467d73a6359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     extracting ngram from test set of size 25000 ...\n",
      "INFO     extracting ngrams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b53e6887bff4fcdadf07301faa126a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     saving pickled data to folder ./data/pickles/ ...\n",
      "INFO     constructing ngram_indexer ...\n",
      "INFO     indexer length 20000\n",
      "INFO     final vocal size: 100002\n",
      "INFO     saving pickled indexer to folder ./data/pickles/ ...\n",
      "INFO     setting each dataset's token indexes\n",
      "INFO     setting each dataset's token indexes\n",
      "INFO     Ep: [1/10], Sp: [128/625], VAcc: 74.42, VLoss: 101.3, TAcc: 77.285, TLoss: 399.3, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [256/625], VAcc: 82.18, VLoss: 83.8, TAcc: 86.25, TLoss: 317.7, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [384/625], VAcc: 86.82, VLoss: 75.7, TAcc: 91.43, TLoss: 277.5, LR: 0.0100\n",
      "INFO     Ep: [1/10], Sp: [512/625], VAcc: 85.52, VLoss: 74.3, TAcc: 92.245, TLoss: 263.2, LR: 0.0100\n",
      "INFO     Ep: [2/10], Sp: [128/625], VAcc: 89.4, VLoss: 69.4, TAcc: 96.65, TLoss: 234.1, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [256/625], VAcc: 89.08, VLoss: 68.7, TAcc: 97.275, TLoss: 227.2, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [384/625], VAcc: 89.48, VLoss: 67.8, TAcc: 98.165, TLoss: 219.7, LR: 0.0095\n",
      "INFO     Ep: [2/10], Sp: [512/625], VAcc: 88.24, VLoss: 68.6, TAcc: 98.49, TLoss: 217.1, LR: 0.0095\n",
      "INFO     Ep: [3/10], Sp: [128/625], VAcc: 89.78, VLoss: 66.7, TAcc: 99.61, TLoss: 206.5, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [256/625], VAcc: 89.74, VLoss: 66.4, TAcc: 99.655, TLoss: 204.5, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [384/625], VAcc: 89.82, VLoss: 66.4, TAcc: 99.765, TLoss: 203.0, LR: 0.0090\n",
      "INFO     Ep: [3/10], Sp: [512/625], VAcc: 89.38, VLoss: 66.1, TAcc: 99.88, TLoss: 200.9, LR: 0.0090\n",
      "INFO     Ep: [4/10], Sp: [128/625], VAcc: 89.68, VLoss: 65.9, TAcc: 99.98, TLoss: 198.9, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [256/625], VAcc: 89.68, VLoss: 65.7, TAcc: 99.985, TLoss: 198.4, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [384/625], VAcc: 89.6, VLoss: 65.7, TAcc: 99.995, TLoss: 197.9, LR: 0.0086\n",
      "INFO     Ep: [4/10], Sp: [512/625], VAcc: 89.7, VLoss: 65.6, TAcc: 100.0, TLoss: 197.6, LR: 0.0086\n",
      "INFO     Ep: [5/10], Sp: [128/625], VAcc: 89.66, VLoss: 65.5, TAcc: 100.0, TLoss: 197.1, LR: 0.0081\n",
      "INFO     Ep: [5/10], Sp: [256/625], VAcc: 89.58, VLoss: 65.5, TAcc: 100.0, TLoss: 196.9, LR: 0.0081\n",
      "INFO     Ep: [5/10], Sp: [384/625], VAcc: 89.5, VLoss: 65.5, TAcc: 100.0, TLoss: 196.8, LR: 0.0081\n",
      "INFO     --- earily stop triggered ---\n",
      "INFO     found historical file, loading the dataframe at ./results/tokenization.p\n",
      "INFO     results saved to ./results/tokenization.p\n",
      "time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "param_overrides={\n",
    "    'REMOVE_STOP_WORDS': True,\n",
    "    'REMOVE_PUNC': True,\n",
    "    'NGRAM_MODE': 'naive'\n",
    "}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='tokenization.p')\n",
    "mm.train()\n",
    "mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "param_overrides={\n",
    "    'REMOVE_STOP_WORDS': True,\n",
    "    'REMOVE_PUNC': True,\n",
    "}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='tokenization.p')\n",
    "mm.train()\n",
    "mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165896476d6e4e71a82e5ef313c9ca13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29039cfb3b114b68a514caa1928c66c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25min 24s\n"
     ]
    }
   ],
   "source": [
    "param_overrides={\n",
    "    'REMOVE_STOP_WORDS': False,\n",
    "    'REMOVE_PUNC': True,\n",
    "}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='tokenization.p')\n",
    "mm.train()\n",
    "mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34db68215035489b9e987040e9d3a951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378ef21869694a41ba7b93574c36557f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26min 25s\n"
     ]
    }
   ],
   "source": [
    "param_overrides={\n",
    "    'REMOVE_STOP_WORDS': True,\n",
    "    'REMOVE_PUNC': False,\n",
    "}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='tokenization.p')\n",
    "mm.train()\n",
    "mm.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbb62a8ce31419cbe04025b73bf9ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8030cc076a994139a24e1a4695ba3142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='NGRAMS', max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 33min\n"
     ]
    }
   ],
   "source": [
    "param_overrides={\n",
    "    'REMOVE_STOP_WORDS': False,\n",
    "    'REMOVE_PUNC': False,\n",
    "}\n",
    "mm = mm_mod.ModelManager(hparams=param_overrides, res_name='tokenization.p')\n",
    "mm.train()\n",
    "mm.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REMOVE_STOP_WORDS</th>\n",
       "      <th>REMOVE_PUNC</th>\n",
       "      <th>NGRAM_MODE</th>\n",
       "      <th>final_val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>spacy</td>\n",
       "      <td>89.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>spacy</td>\n",
       "      <td>90.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>spacy</td>\n",
       "      <td>89.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>spacy</td>\n",
       "      <td>90.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REMOVE_STOP_WORDS  REMOVE_PUNC NGRAM_MODE  final_val_acc\n",
       "0               True         True      spacy          89.46\n",
       "1              False         True      spacy          90.78\n",
       "2               True        False      spacy          89.50\n",
       "3              False        False      spacy          90.64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.9 ms\n"
     ]
    }
   ],
   "source": [
    "fp = r'./results/tokenization.p'\n",
    "df = pkl.load(open(fp, 'rb'))[['REMOVE_STOP_WORDS', 'REMOVE_PUNC', 'NGRAM_MODE', 'final_val_acc']]\n",
    "df = df[df['NGRAM_MODE'] == 'spacy']\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
