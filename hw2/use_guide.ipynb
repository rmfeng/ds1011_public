{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a use guide to demo the functionality in 0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import basic_conf as conf\n",
    "from libs import ModelManager as mm\n",
    "from config.constants import HyperParamKey\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to use the text example please load your home work 1 data like this:\n",
    "\n",
    "![require_data](img/required_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How to init the logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter when initializing logger will determine the log level for the rest of the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in this example we init logger with level = INFO and see that the info logs get outputted\n",
    "conf.init_logger(logging.INFO, logfile=None)\n",
    "logger = logging.getLogger('__main__')\n",
    "mgr = mm.ModelManager(mode='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this example we init logger with level = WARNING, we see that all the info logs are suppressed\n",
    "conf.init_logger(logging.WARNING, logfile=None)\n",
    "logger = logging.getLogger('__main__')\n",
    "mgr = mm.ModelManager(mode='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2nd parameter in logger controls where the log file lives, by default this is mt.log in root\n",
    "\n",
    "If you pass None, like here, then no output will be written to the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in this example we init logger the default logfile='mt.log' parameter and see that the log was written to the file\n",
    "conf.init_logger(logging.INFO)\n",
    "logger = logging.getLogger('__main__')\n",
    "mgr = mm.ModelManager(mode='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head mt.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initializing the Model Manager in notebook or console mode\n",
    "\n",
    "Since the tqdm handler works differently in notebook vs console, we had to branch the execution based on where we are working. Here I will initialize in in 'notebook' mode, by default it operates in console mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let me first turn off the logging to mt.log\n",
    "conf.init_logger(logging.INFO, logfile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this line inits the ModelManager, and puts all of the default parameters into memory\n",
    "# mode='notebook' is passed to initialize in notebook mode, if nothing is passed then, it goes in console mode\n",
    "mgr = mm.ModelManager(mode='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 3 types of parameters\n",
    "All of these parameters are passed into the Model constructor when creating a new_model\n",
    "\n",
    "- **Hyperparameters** (self.hparam): the standard hyperparameters used in your model, such as batch_size, embedding_dim, lr ... etc. (The keys are in config.constants.HyperParamKey)\n",
    "- **Control Parameters** (self.cparams): controls how the model in/out behaves, these will include paths, and controls for when the model runs the save routine, whether to save each new best model, or save each epoch, or both. (The keys are in config.constants.PathKey and ControlKey)\n",
    "- **Loader Parameters** (self.lparams): these are parameters that the model constructor will need to know to initialize, so far I found only the act_vocab_size was needed as when running the loader, even with a specified vocab size, the actual vocab size that gets loaded is dependent on what is in the data. Therefore these parameters can only be set after running the load routine. I've specified for the load routines to return a dict of key:param so that this variable can be set. (The keys are in config.constants.LoaderParamKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calling the data loader\n",
    "\n",
    "There is a register at mm.loaderRegister. It will contain a loader_list of available loaders and attributes with the names of the available loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mm.loaderRegister.loader_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To call the load function using a specifict loader, just give the ModelManager.load_data function the registry key for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.load_data(mm.loaderRegister.IMDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Adding new dataloader handlers\n",
    "\n",
    "- add the implementation child class of libs.data_loaders.BaseLoader to libs.data_loaders\n",
    "- add the registry key to libs.data_loaders.registry\n",
    "\n",
    "A example dataloader used for homework 1 is provided in libs.data_loaders.ImdbLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initializing Models\n",
    "\n",
    "New models are initialized with the ModelManager.new_model function, the parameter is the key in the model registry. All of the parameters on the ModelManager is then passed to the Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mm.modelRegister.model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mgr.new_model(mm.modelRegister.BagOfWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Important generalized concepts on Models:\n",
    "\n",
    "Each epoch is subdivided into \"iteration\" with each iteration as a collection of n batches. n is determined by the self.hparams.train_loop_check_freq parameter.\n",
    "\n",
    "The check_early_stop function is called for each iteration. \n",
    "\n",
    "The BaseModel class implements the basic training loop as well as save and load functions, save/load function folder is determined by the BaseModel.label property\n",
    "\n",
    "Each model will have 2 training curves: self.iter_curves is saved each training \"iteration\". self.epoch_curves is saved at each epoch\n",
    "\n",
    "the self.model property on the BaseModel or child model class should point to the graph (nn.Module) that implements forward and backward passing\n",
    "\n",
    "The child model class (in the example case: BagOfWords) should implement:\n",
    "- eval_model() which is a forward pass but in eval mode (no drop out, no autograd)\n",
    "- check_early_stop() which is called at each training iteration\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here our hyperparameter for number of epoch was set only to 1, so the loop runs just 1 epoch\n",
    "mgr.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we have enabled saving at each epoch and each best, we should find 2 saved files:\n",
    "- model_saves/checkpoint.tar - saved after the last **completed** epoch\n",
    "- model_saves/model_best.tar - saved after a new best iteration was achieved (best on val acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also explicitly save the model with a comment in markdown format, \n",
    "# and can override the default filename = 'checkpoint.tar'\n",
    "comment = \"\"\"\n",
    "## Trial 1\n",
    "\n",
    "I ran the basic training model for 1 iteration and wanted to demonstrate the save functionality\n",
    "\n",
    "**hope you all find this useful!**\n",
    "\"\"\"\n",
    "\n",
    "mgr.save_model(comment, fn='mysave.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the model to model_saves/<model_label>/ and adds a README.md with the comment in that folder - once checked in, the readme.md will be automatically rendered on github.\n",
    "\n",
    "In this case, my label was the default \"scratch\" so the model was saved to model_saves/scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b Loading\n",
    "\n",
    "If I wanted to continue to train that model, I can load it like this (first we'll clear the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.model = None  # gc-ing the existing model\n",
    "\n",
    "# reinit\n",
    "mgr.new_model(mm.modelRegister.BagOfWords, nolog=True)\n",
    "\n",
    "# loading state\n",
    "mgr.load_model(which_model='mysave.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c. Continuing Training\n",
    "\n",
    "We can add more epochs to the model and continue to train it:\n",
    "\n",
    "**Note that the model continues where it left off in epoch 2!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.model.add_epochs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing Training Curves\n",
    "\n",
    "I implemented a graph_training_curves() method just to see the training/val acc and loss in a graph\n",
    "\n",
    "If the ModelManager is in notebook mode, it will output results here, if console it will output results to the model folder: model_saves/<model_label>/\n",
    "\n",
    "It can graph either the iteration curves or the epoch curves: see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.graph_training_curves()  # no mode param defaults to iteration mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.graph_training_curves(mode=mgr.GRAPH_MODE_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reporting other training metrics back up to ModelManager\n",
    "\n",
    "models should collect their own results values in self.output_dict in {'field': value} format.\n",
    "\n",
    "After **each** mgr.train() call the ModelManager will collect these outputs\n",
    "\n",
    "you can use these results to do your hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comprehensive example of training multiple models and collecting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resetting the manager\n",
    "mgr = mm.ModelManager(mode='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# simple grid search\n",
    "lr_list = [0.1, 0.01]\n",
    "epoch_list = [1, 2]\n",
    "\n",
    "for lr in lr_list:\n",
    "    for epoch in epoch_list:\n",
    "        # update hparams\n",
    "        hparam_overrides = {HyperParamKey.LR:lr, HyperParamKey.NUM_EPOCH:epoch}\n",
    "        mgr.hparams.update(hparam_overrides)\n",
    "        \n",
    "        # load data is needed in the loop if the data loaded is dependant on hparams, otherwise can put outside\n",
    "        mgr.load_data(mm.loaderRegister.IMDB)  \n",
    "        \n",
    "        # reinits a model with\n",
    "        mgr.new_model(mm.modelRegister.BagOfWords)\n",
    "        \n",
    "        # trains and collects results\n",
    "        mgr.train()\n",
    "        \n",
    "        # free up memory\n",
    "        mgr.dump_model()  \n",
    "        \n",
    "mgr.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can save the results\n",
    "mgr.get_results().to_csv('model_saves/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
