{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from libs import ModelManager as mm\n",
    "from config import basic_conf as conf\n",
    "import logging\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-10-27 15:25:43] [INFO] Initializing Model Manager, version 0.4.0 ...\n",
      "[2018-10-27 15:25:43] [INFO] \n",
      "=== Models Available ===\n",
      "BagOfWords\n",
      "NLIRNN\n",
      "========================\n",
      "[2018-10-27 15:25:43] [INFO] \n",
      "=== Loaders Available ===\n",
      "IMDB\n",
      "SNLI\n",
      "========================\n",
      "[2018-10-27 15:25:43] [INFO] \n",
      "*********** Model Manager Details ***********\n",
      "-- self.hparams.num_epochs = 10\n",
      "-- self.hparams.lr = 0.01\n",
      "-- self.hparams.voc_size = 100000\n",
      "-- self.hparams.train_loop_check_freq = 10\n",
      "-- self.hparams.dropout_rnn = 0.5\n",
      "-- self.hparams.dropout_fc = 0.5\n",
      "-- self.hparams.batch_size = 256\n",
      "-- self.hparams.fc_hidden_size = 50\n",
      "-- self.hparams.rnn_hidden_size = 50\n",
      "-- self.hparams.rnn_num_layers = 1\n",
      "-- self.hparams.check_early_stop = True\n",
      "-- self.hparams.es_look_back = 10\n",
      "-- self.hparams.es_req_prog = 0.01\n",
      "-- self.hparams.optim_enc = <class 'torch.optim.adam.Adam'>\n",
      "-- self.hparams.optim_dec = <class 'torch.optim.adam.Adam'>\n",
      "-- self.hparams.scheduler = <class 'torch.optim.lr_scheduler.ExponentialLR'>\n",
      "-- self.hparams.scheduler_gamma = 0.95\n",
      "-- self.hparams.criterion = <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "-- self.cparams.save_best_model = True\n",
      "-- self.cparams.save_each_epoch = True\n",
      "-- self.cparams.ignore_params = ['pre_trained_vecs']\n",
      "-- self.cparams.nli_train_path = data/nli/snli_train.tsv\n",
      "-- self.cparams.nli_val_path = data/nli/snli_val.tsv\n",
      "-- self.cparams.pretrained_path = data/nli/wiki-news-300d-1M.vec\n",
      "-- self.cparams.model_saves = model_saves/\n",
      "-- self.lparams = None\n",
      "-- self.model = None\n",
      "-- self.dataloader = None\n",
      "-- self.results = []\n",
      "-- self.mode = notebook\n",
      "-- self.tqdm = <function tqdm_notebook at 0x7f3d555c9c80>\n",
      "-- self.device = cuda:0\n",
      "************ End of Model Manager Details ************\n"
     ]
    }
   ],
   "source": [
    "conf.init_logger(logging.INFO, logfile=None)\n",
    "mgr = mm.ModelManager(mode='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-10-27 15:25:44] [INFO] Loading data using SNLI ...\n",
      "[2018-10-27 15:25:44] [INFO] loading raw training data set ...\n",
      "[2018-10-27 15:25:44] [INFO] loading raw training data set ...\n",
      "[2018-10-27 15:25:44] [INFO] loading pre-trained word vectors, building vocab ...\n",
      "[2018-10-27 15:25:57] [INFO] converting training set to index ...\n",
      "[2018-10-27 15:25:58] [INFO] converting val set to index ...\n",
      "[2018-10-27 15:25:58] [INFO] piping data into pytorch DataLoaders ...\n"
     ]
    }
   ],
   "source": [
    "mgr.load_data(mm.loaderRegister.SNLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-10-27 15:25:58] [INFO] \n",
      "*********** Model: scratch Details ***********\n",
      "-- self.label = scratch\n",
      "-- self.hparams.num_epochs = 10\n",
      "-- self.hparams.lr = 0.01\n",
      "-- self.hparams.voc_size = 100000\n",
      "-- self.hparams.train_loop_check_freq = 10\n",
      "-- self.hparams.dropout_rnn = 0.5\n",
      "-- self.hparams.dropout_fc = 0.5\n",
      "-- self.hparams.batch_size = 256\n",
      "-- self.hparams.fc_hidden_size = 50\n",
      "-- self.hparams.rnn_hidden_size = 50\n",
      "-- self.hparams.rnn_num_layers = 1\n",
      "-- self.hparams.check_early_stop = True\n",
      "-- self.hparams.es_look_back = 10\n",
      "-- self.hparams.es_req_prog = 0.01\n",
      "-- self.hparams.optim_enc = <class 'torch.optim.adam.Adam'>\n",
      "-- self.hparams.optim_dec = <class 'torch.optim.adam.Adam'>\n",
      "-- self.hparams.scheduler = <class 'torch.optim.lr_scheduler.ExponentialLR'>\n",
      "-- self.hparams.scheduler_gamma = 0.95\n",
      "-- self.hparams.criterion = <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "-- self.lparams.act_vocab_size = 100002\n",
      "-- self.lparams.pre_trained_vecs = [[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.34579698  0.23973431  0.11749783 ...  0.05458989  0.08361439\n",
      "   0.08434543]\n",
      " [ 0.1073      0.0089      0.0006     ...  0.005       0.1173\n",
      "  -0.04      ]\n",
      " ...\n",
      " [ 0.1364     -0.0823      0.0268     ...  0.0146     -0.1281\n",
      "   0.1004    ]\n",
      " [ 0.3732      0.0413      0.179      ... -0.0461     -0.0787\n",
      "  -0.0635    ]\n",
      " [-0.0405     -0.0471      0.1363     ...  0.2969     -0.223\n",
      "  -0.0133    ]]\n",
      "-- self.lparams.embedding_dim = 300\n",
      "-- self.lparams.num_classes = 3\n",
      "-- self.cparams.save_best_model = True\n",
      "-- self.cparams.save_each_epoch = True\n",
      "-- self.cparams.ignore_params = ['pre_trained_vecs']\n",
      "-- self.cparams.nli_train_path = data/nli/snli_train.tsv\n",
      "-- self.cparams.nli_val_path = data/nli/snli_val.tsv\n",
      "-- self.cparams.pretrained_path = data/nli/wiki-news-300d-1M.vec\n",
      "-- self.cparams.model_saves = model_saves/\n",
      "-- self.cparams.model_path = model_saves/scratch/\n",
      "-- self.cur_epoch = 0\n",
      "-- self.model = None\n",
      "-- self.optim = None\n",
      "-- self.scheduler = None\n",
      "-- self.iter_curves.train_acc = []\n",
      "-- self.iter_curves.train_loss = []\n",
      "-- self.iter_curves.val_acc = []\n",
      "-- self.iter_curves.val_loss = []\n",
      "-- self.epoch_curves.train_acc = []\n",
      "-- self.epoch_curves.train_loss = []\n",
      "-- self.epoch_curves.val_acc = []\n",
      "-- self.epoch_curves.val_loss = []\n",
      "-- self.output_dict.num_epochs = 10\n",
      "-- self.output_dict.lr = 0.01\n",
      "-- self.output_dict.voc_size = 100000\n",
      "-- self.output_dict.train_loop_check_freq = 10\n",
      "-- self.output_dict.dropout_rnn = 0.5\n",
      "-- self.output_dict.dropout_fc = 0.5\n",
      "-- self.output_dict.batch_size = 256\n",
      "-- self.output_dict.fc_hidden_size = 50\n",
      "-- self.output_dict.rnn_hidden_size = 50\n",
      "-- self.output_dict.rnn_num_layers = 1\n",
      "-- self.output_dict.check_early_stop = True\n",
      "-- self.output_dict.es_look_back = 10\n",
      "-- self.output_dict.es_req_prog = 0.01\n",
      "-- self.output_dict.optim_enc = <class 'torch.optim.adam.Adam'>\n",
      "-- self.output_dict.optim_dec = <class 'torch.optim.adam.Adam'>\n",
      "-- self.output_dict.scheduler = <class 'torch.optim.lr_scheduler.ExponentialLR'>\n",
      "-- self.output_dict.scheduler_gamma = 0.95\n",
      "-- self.output_dict.criterion = <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "-- self.output_dict.act_vocab_size = 100002\n",
      "-- self.output_dict.embedding_dim = 300\n",
      "-- self.output_dict.num_classes = 3\n",
      "************ End of Model: scratch Details ************\n",
      "[2018-10-27 15:26:00] [INFO] New Model initialized: /scratch, all model output files will be saved here: model_saves/scratch/\n"
     ]
    }
   ],
   "source": [
    "mgr.new_model(mm.modelRegister.NLIRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-10-27 15:26:00] [INFO] stepped scheduler to epoch = 1\n",
      "[2018-10-27 15:26:08] [INFO] Ep:1/10, Bt:10/391, VAcc:44.10, VLoss:4.4, TAcc:44.52, TLoss:424.8, LR:0.0100\n",
      "[2018-10-27 15:26:17] [INFO] Ep:1/10, Bt:20/391, VAcc:52.50, VLoss:4.2, TAcc:53.38, TLoss:408.0, LR:0.0100\n",
      "[2018-10-27 15:26:28] [INFO] Ep:1/10, Bt:30/391, VAcc:56.50, VLoss:4.0, TAcc:55.53, TLoss:392.8, LR:0.0100\n",
      "[2018-10-27 15:26:39] [INFO] Ep:1/10, Bt:40/391, VAcc:56.20, VLoss:4.0, TAcc:57.30, TLoss:393.7, LR:0.0100\n",
      "[2018-10-27 15:26:48] [INFO] Ep:1/10, Bt:50/391, VAcc:54.60, VLoss:4.0, TAcc:56.61, TLoss:394.8, LR:0.0100\n",
      "[2018-10-27 15:26:57] [INFO] Ep:1/10, Bt:60/391, VAcc:58.00, VLoss:3.9, TAcc:59.20, TLoss:385.3, LR:0.0100\n",
      "[2018-10-27 15:27:08] [INFO] Ep:1/10, Bt:70/391, VAcc:57.40, VLoss:3.9, TAcc:59.99, TLoss:381.3, LR:0.0100\n",
      "[2018-10-27 15:27:17] [INFO] Ep:1/10, Bt:80/391, VAcc:59.10, VLoss:3.9, TAcc:60.45, TLoss:381.2, LR:0.0100\n",
      "[2018-10-27 15:27:28] [INFO] Ep:1/10, Bt:90/391, VAcc:57.10, VLoss:3.9, TAcc:59.90, TLoss:382.1, LR:0.0100\n",
      "[2018-10-27 15:27:37] [INFO] Ep:1/10, Bt:100/391, VAcc:60.10, VLoss:3.9, TAcc:61.07, TLoss:375.3, LR:0.0100\n",
      "[2018-10-27 15:27:49] [INFO] Ep:1/10, Bt:110/391, VAcc:59.60, VLoss:3.9, TAcc:61.80, TLoss:375.4, LR:0.0100\n",
      "[2018-10-27 15:27:57] [INFO] Ep:1/10, Bt:120/391, VAcc:59.40, VLoss:3.9, TAcc:60.97, TLoss:379.1, LR:0.0100\n",
      "[2018-10-27 15:28:06] [INFO] Ep:1/10, Bt:130/391, VAcc:59.50, VLoss:3.8, TAcc:61.59, TLoss:373.1, LR:0.0100\n",
      "[2018-10-27 15:28:15] [INFO] Ep:1/10, Bt:140/391, VAcc:59.70, VLoss:3.9, TAcc:61.60, TLoss:377.8, LR:0.0100\n",
      "[2018-10-27 15:28:24] [INFO] Ep:1/10, Bt:150/391, VAcc:61.60, VLoss:3.8, TAcc:62.72, TLoss:372.0, LR:0.0100\n",
      "[2018-10-27 15:28:35] [INFO] Ep:1/10, Bt:160/391, VAcc:60.60, VLoss:3.8, TAcc:62.55, TLoss:371.9, LR:0.0100\n",
      "[2018-10-27 15:28:44] [INFO] Ep:1/10, Bt:170/391, VAcc:60.20, VLoss:3.9, TAcc:61.74, TLoss:375.1, LR:0.0100\n",
      "[2018-10-27 15:28:53] [INFO] Ep:1/10, Bt:180/391, VAcc:61.20, VLoss:3.8, TAcc:62.23, TLoss:368.2, LR:0.0100\n",
      "[2018-10-27 15:29:02] [INFO] Ep:1/10, Bt:190/391, VAcc:61.50, VLoss:3.8, TAcc:62.91, TLoss:367.9, LR:0.0100\n",
      "[2018-10-27 15:29:10] [INFO] Ep:1/10, Bt:200/391, VAcc:61.90, VLoss:3.9, TAcc:63.57, TLoss:373.3, LR:0.0100\n",
      "[2018-10-27 15:29:22] [INFO] Ep:1/10, Bt:210/391, VAcc:61.80, VLoss:3.8, TAcc:63.78, TLoss:364.6, LR:0.0100\n",
      "[2018-10-27 15:29:30] [INFO] Ep:1/10, Bt:220/391, VAcc:61.20, VLoss:3.8, TAcc:62.70, TLoss:372.5, LR:0.0100\n",
      "[2018-10-27 15:29:39] [INFO] Ep:1/10, Bt:230/391, VAcc:64.20, VLoss:3.8, TAcc:63.47, TLoss:371.4, LR:0.0100\n",
      "[2018-10-27 15:29:51] [INFO] Ep:1/10, Bt:240/391, VAcc:63.10, VLoss:3.7, TAcc:64.56, TLoss:362.4, LR:0.0100\n",
      "[2018-10-27 15:29:59] [INFO] Ep:1/10, Bt:250/391, VAcc:62.30, VLoss:3.8, TAcc:64.15, TLoss:370.1, LR:0.0100\n",
      "[2018-10-27 15:30:08] [INFO] Ep:1/10, Bt:260/391, VAcc:62.20, VLoss:3.8, TAcc:64.52, TLoss:366.6, LR:0.0100\n",
      "[2018-10-27 15:30:17] [INFO] Ep:1/10, Bt:270/391, VAcc:62.30, VLoss:3.7, TAcc:64.57, TLoss:362.8, LR:0.0100\n",
      "[2018-10-27 15:30:26] [INFO] Ep:1/10, Bt:280/391, VAcc:63.30, VLoss:3.8, TAcc:64.95, TLoss:366.3, LR:0.0100\n",
      "[2018-10-27 15:30:35] [INFO] Ep:1/10, Bt:290/391, VAcc:63.00, VLoss:3.8, TAcc:64.75, TLoss:366.6, LR:0.0100\n",
      "[2018-10-27 15:30:44] [INFO] Ep:1/10, Bt:300/391, VAcc:61.90, VLoss:3.8, TAcc:64.09, TLoss:366.8, LR:0.0100\n",
      "[2018-10-27 15:30:53] [INFO] Ep:1/10, Bt:310/391, VAcc:62.80, VLoss:3.8, TAcc:65.00, TLoss:365.2, LR:0.0100\n",
      "[2018-10-27 15:31:02] [INFO] Ep:1/10, Bt:320/391, VAcc:60.80, VLoss:3.8, TAcc:64.87, TLoss:368.5, LR:0.0100\n",
      "[2018-10-27 15:31:10] [INFO] Ep:1/10, Bt:330/391, VAcc:61.80, VLoss:3.8, TAcc:65.18, TLoss:364.7, LR:0.0100\n",
      "[2018-10-27 15:31:10] [INFO] --- stopping training due to early stop ---\n",
      "[2018-10-27 15:31:21] [INFO] stepped scheduler to epoch = 2\n",
      "[2018-10-27 15:31:32] [INFO] stepped scheduler to epoch = 3\n",
      "[2018-10-27 15:31:44] [INFO] stepped scheduler to epoch = 4\n",
      "[2018-10-27 15:31:55] [INFO] stepped scheduler to epoch = 5\n",
      "[2018-10-27 15:32:06] [INFO] stepped scheduler to epoch = 6\n",
      "[2018-10-27 15:32:17] [INFO] stepped scheduler to epoch = 7\n",
      "[2018-10-27 15:32:29] [INFO] stepped scheduler to epoch = 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-97bb04dac4d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GradSchool/nlpDS1011/ds1011/hw2/libs/ModelManager.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"\"\" continue to train the current model \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GradSchool/nlpDS1011/ds1011/hw2/libs/models/NLIRNN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, loader, tqdm_handler)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;31m# appending to epock trackers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_curves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_LOSS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_curves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_ACC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GradSchool/nlpDS1011/ds1011/hw2/libs/models/NLIRNN.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# good practice to set the model to evaluation mode (no dropout)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msent1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mcur_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GradSchool/nlpDS1011/ds1011/hw2/libs/models/modules/RNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent1, sent2, len1, len2)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mhidden_vec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_rnn_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mrnn_out1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_vec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_vec1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# RNN handles hidden state init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# feeding the 2nd sent through the GRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             dropout_ts)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mgr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
